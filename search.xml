<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[é‚¦é‚¦å’ŒçŒªçŒªçš„49ä»¶å°äº‹]]></title>
    <url>%2F2019%2F08%2F07%2F49%E4%BB%B6%E5%B0%8F%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[é‚¦é‚¦å’ŒçŒªçŒªçš„49ä»¶å°äº‹ ç¬¦é¦™çŒªå¸¸å¸¸å“€æ„æˆ–æ¬¢å–œåœ°ç«™åœ¨é•œå­å‰ï¼šè¿™æ ·çœ‹æˆ‘çš„è…¿è¿˜æ˜¯æŒºç»†çš„å˜› or è¿™æ ·çœ‹æˆ‘çš„è…¿è¿˜æ˜¯æœ‰ç‚¹ç²—å“¦ æˆ‘ä»¬ä¿©æ€»æ˜¯çˆ±ç»™å¯¹æ–¹å–å„ç§å¥‡æ€ªçš„å¤–å·ï¼šçŒªçŒªã€é¦™çŒªã€å¦®å¦®ã€ä¸­ç¯åä¸‰å¦®ã€ç“œç“œã€‚ æˆ‘ä»¬åº”è¯¥æ˜¯å®‡å®™é‡Œæœ€çˆ±å–å¥¶èŒ¶çš„å¤«å¦‡äº†ï¼Œåœ¨å·´é»å®ä¹ çš„æ—¶å€™ï¼Œæ¯æ¬¡ä¸‹ç­å°±åšåŠä¸ªå°æ—¶åœ°é“å»å–å¥¶èŒ¶ã€‚ æ²¡äº‹ç…ç…è‡ªå·±çš„é’»æˆ’ï¼šè¿™æ ·çœ‹è¿™ä¸ªé’»æˆ’è¿˜æ˜¯æŒºå¤§çš„ or è¿™æ ·çœ‹è¿™ä¸ªé’»æˆ’å¥½å°å“¦ å¸¸å¹´ç»™èˆªç©ºå…¬å¸åšè´¡çŒ®çš„æˆ‘ä¿©ï¼Œæœ‰ä¸€æ¬¡è‹±å›½é›ªç¾ï¼Œæˆ‘è¿˜è¯•å›¾ä»æ–¯å›¾åŠ ç‰¹è½¬æœºï¼Œç»“æœèˆªç­å–æ¶ˆè¢«æ»ç•™äº†ï¼Œé€›äº†ä¸€å¤©çš„å¥”é©°åšç‰©é¦†ã€‚ å¤§å­¦çš„æ—¶å€™ï¼Œæœ‰ä¸€æ¬¡ç»™ä½ é€é¥­ï¼Œçœ‹åˆ°ä½ ç“œå…®å…®åœ°è¶´é‚£ç¡è§‰ã€‚ ä¸€èµ·å»çœ‹Runningmançš„æ¼”å”±ä¼šï¼Œé‚£æ—¶è¿˜æ˜¯é•¿å‘é£˜é£˜çš„æˆ‘ã€‚ ä¸¤ä¸ªæœˆæ³•è¯­æ°´å¹³çš„ç¬¦çŒªçŒªï¼Œä¹°äº†ä¸€ä¸ªâ€câ€™est le vieâ€ï¼Œé˜´é˜³æ€§æé”™äº†ï¼Œä½†æ˜¯è´´åœ¨å¢™ä¸Šå–ä¸ä¸‹æ¥äº†ï¼Œå¸¸å¸¸è¢«æˆ‘å˜²ç¬‘ã€‚ è®°å¾—é‚£ä¼šåœ¨æ³•å›½è€ï¼Œç»å¸¸æ‰¾å°å§å§å¸®æˆ‘ä»¬æ‹ç…§ï¼Œæ‰¿è’™å°å§å§å„ç§è¢«æ’’ç‹—ç²®è€Œä¸å¼ƒã€‚ æœ‰ä¸€æ¬¡è·¯è¿‡åœ°é“çš„ä¸€ä¸ªå¨ƒå¨ƒæœºï¼Œçœ‹åˆ°è¿™ä¸ªè¥¿ç“œä¹–çš„å¾ˆï¼ŒèŠ±äº†40å—æ‰æŠ“åˆ°~ç°åœ¨è¿™ä¸ªç“œèººåœ¨æˆ‘åºŠä¸Šè¢«å½“åšä¸´æ—¶é æ•å“ˆå“ˆã€‚ ç¬¦çŒªçŒªæ˜¯çœŸçš„çˆ±ç¡ï¼Œç¡ç€çš„æ—¶å€™å°±åƒä¸€ä¸ªå°æ†¨æ†¨ï¼Œçœ¼ç›å¤ªå¤§é—­ä¸ä¸Šï¼Œç„¶åå¼ ç€ä¸ªå˜´ã€‚ äº”ä¸€èŠ‚å»é¦™æ¸¯è€ï¼Œæ™šä¸Šåˆ°äº†é…’åº—ï¼Œæˆ‘åœ¨èµ¶å·¥å†™ä»£ç ï¼Œç¬¦çŒªçŒªç¬‘å˜»å˜»åœ°æŠ“ç€æˆ‘æ‹ç…§ï¼Œç„¶åè€èµ–ä¸è®©æˆ‘å†™ã€‚ ä¸€èµ·å»å½•æˆ‘ä»¬è‡ªå·±å†™çš„æ­Œï¼Œç„¶åå©šç¤¼ç°åœºå”±çš„æ—¶å€™ç–¯ç‹‚å¿˜è¯ï¼ŒOrzã€‚ æ›¾ç»æˆ‘ä¹Ÿæ˜¯ä¸€ä¸ªå¤šä¹ˆçš„swagçš„boyï¼Œå¦‚ä»Šè¢«ç”Ÿæ´»æ‘§æ®‹äº†ã€‚å•Šã€‚ ç¬¦çŒªçŒªç»™æˆ‘é€è¿‡ä¸€ä¸ªçˆ±ä¸å ¡ç‰¹è‰²å›´å·¾ï¼Œæœ¬æ¥æƒ…ä¾£æ¬¾ï¼Œç»“æœå¥¹çš„å°±è¢«å¥¹æä¸¢äº†ï¼ŒçœŸå‚»ã€‚ æˆ‘ä»¬å»å·´é»åœ£æ¯é™¢é‡Œè€ï¼Œå¦‚ä»ŠNotre Dameè¢«çƒ§æ‰å•¦ï¼Œé‡å»ºå¥½äº†ï¼Œæˆ‘ä»¬å¸¦ç€å¨ƒä¸€èµ·å»ã€‚ å»å·´é»åœ£æ¯é™¢è€ï¼Œå‘ç°æˆ‘ä»¬æ²¡æœ‰åˆç…§ï¼Œç„¶åæˆ‘ä¸€ä¸ªåƒç´ ç‚¹ä¸€ä¸ªåƒç´ ç‚¹çš„æ‹¼å›¾ï¼Œå“ˆå“ˆå“ˆã€‚ é‚£æ—¶å€™æˆ‘è¿˜åœ¨ä¸Šæµ·ä¸Šç­ï¼Œæœ‰ä¸€æ¬¡ä¸‹ç­äº†å»å…¬å›­æ•£æ­¥ï¼Œç„¶åæ‹æ‹æ‹ç…§ï¼Œç„¶åæˆ‘è¢«å«Œå¼ƒå«Œå¼ƒå«Œå¼ƒï¼Œä¸€å·¥ä½œå°±å¼€å§‹é•¿èƒ–äº†ã€‚ å¤©å¤ªçƒ­ï¼Œè¢«çŒªğŸ·æ²¹è’™äº†å¿ƒï¼Œå‰ƒäº†æ¿å¯¸ï¼Œä¹Ÿæ˜¯æœ‰å‹‡æ°”äº†ã€‚çœ‹èµ·æ¥è¿˜æ˜¯æŒºç²¾ç¥æŒºå¸…çš„ã€‚ æˆ‘ä¿©åšä½œçš„ä¸­å¼å©šç¤¼ç°åœºï¼Œæ®è¯´æˆ‘å½“æ—¶è¡¨ç°ç‰¹ä¸¥è‚ƒç´§å¼ ï¼Œæ˜æ˜æ˜¯å¸ˆçˆ·è®©æˆ‘ä¸è¦éœ²ç‰™ç¬‘ä¸«ã€‚ ç”±äºå¤©å¤ªå†·ï¼Œè£¹æˆé˜¿æ‹‰ä¼¯å°‘å¥³ï¼ŒæŒç€Channelçš„ç¦çŒªçŒªã€‚ å¸¸å¹´å¸¦å„ç§äº²æˆšå»ä¸œæ–¹æ˜ç çš„æˆ‘ä»¬ï¼Œä¹Ÿæœ‰äº†ä¸€å¼ ç‚«é…·çš„åˆå½±ã€‚ è®°å¾—2018å¹´1æœˆ24å·ï¼Œä½ çªç„¶å‘æˆ‘â€œè¡¨ç™½â€ï¼Œç„¶åæˆ‘å°±ç­”åº”ä½ äº†ã€‚å“ˆå“ˆå“ˆå“ˆå“ˆå“ˆï¼Œæˆªå›¾ä¸ºè¯ã€‚ æ„å¤§åˆ©éª—å­å¤ªå¤šäº†ï¼Œé˜²ä¸èƒœé˜²ï¼Œå–„è‰¯å¤©çœŸçš„æˆ‘ä»¬å°±è¿™ä¹ˆè¢«éª—äº†ä¸¤æ¬§ã€‚ å¿ƒå¿ƒå¿µå¿µçš„â€œèŠéº»ç³Šâ€ï¼Œå°æ—¶å€™å¤šä¹ˆé˜”çˆ±å¤šä¹ˆä¹–ï¼Œè¿˜ä»¥ä¸ºé•¿ä¸å¤§å‘¢ï¼Œç»“æœç°åœ¨å˜æˆäº†æ‘ä¸­ä¸€éœ¸ã€‚ ä¸çŸ¥é“ä¸ºå•¥ï¼Œä½ æ€»æ˜¯å–œæ¬¢ç©¿æˆ‘çš„å„ç±»ç¡è¡£ï¼Œå¯¼è‡´æˆ‘å¸¸å¹´æ— ç¡è¡£å¯ç©¿ã€‚ ä¸€å…±å¥½åƒå»äº†äº”æ¬¡è¿˜æ˜¯å…­æ¬¡çˆ±ä¸å ¡ï¼Œæ¯æ¬¡éƒ½è¯´è¦å»é“ç‹åº§ï¼Œæ¯æ¬¡éƒ½å› ä¸ºä¸‹é›¨æˆ–è€…æ‡’æ²¡å»ï¼Œç•™ä¸‹äº†ä¸€ä¸ªé—æ†¾ã€‚ æˆ‘ä»¬ä¹Ÿæ˜¯çˆ±è¿åŠ¨å¤«å¦‡ï¼Œå„ç§ç¯®çƒã€æ¸¸æ³³ã€ä¿é¾„çƒã€‚ å»åšæ‰‹å·¥ï¼Œé™¶ç“·æ¯å­ä¸€ä¸ªå¤§ä¸€ä¸ªå°ï¼Œç­‰ç”µå°å··ç­‰åˆ°äº†æ™šä¸Šåç‚¹å¤šã€‚ è¿˜è®°å¾—ä½ å°çƒæ‰“ä¸è¿‡æˆ‘ï¼Œåœ¨é‚£é‡Œè€èµ–ç”Ÿæ°”ï¼Œè¯´æˆ‘å˜²ç¬‘ä½ ï¼Œæ˜æ˜åƒé¸¡çš„æ—¶å€™ä¹Ÿå¸¸å¹´å˜²ç¬‘æˆ‘ã€‚ åœ¨å·´å˜å²›é¡¶ç€â€œåçº§â€å¤§é£æ‹å©šçº±ç…§ï¼ŒçœŸçš„çä¸å¼€çœ¼å•Šï¼Œä½ å‚»ç¬‘çš„æ—¶å€™ç¾ç¾å“’ã€‚ ä¸€è¾¹è·Ÿæˆ‘è§†é¢‘ï¼Œä¸€è¾¹ç“œå…®å…®çš„åƒé¥­ï¼Œä½ åƒé¥­çš„æ—¶å€™çœŸçš„æŒºé¦™çš„ï¼Œè®©äººçœ‹äº†è¶…æœ‰é£Ÿæ¬²ã€‚ğŸ¤¤ æˆ‘ä»¬ä¹Ÿæ›¾åœ¨å·´é»è¡—å¤´éª‘è¿‡å…±äº«å•è½¦ï¼Œæ²¿ç€å¡çº³æ²³ï¼Œå±å‘€å±å‘€ï¼Œé‚£å¤©çš„å¤•é˜³ç‰¹åˆ«ç¾ã€‚ ç¬¬ä¸€æ¬¡æƒ…äººèŠ‚ï¼Œä½ æ¥å·´é»è€ï¼Œç»™ä½ åšäº†ä¸€æ¡Œå­èœï¼Œè¿˜è·Ÿå¦ˆå¦ˆå­¦äº†å››å·ç‰¹è‰²ç³–é†‹æ’éª¨ï¼Œä½ ç…ç…ä½ åƒçš„å¤šé¦™ï¼Œåé¢å°±è€å«Œå¼ƒæˆ‘åšçš„ä¸å¥½åƒäº†ã€‚ å˜‰å®šé€›gaigaiï¼Œæ‹äº†ä¸€å¼ å¾ˆç¾çš„ç…§ç‰‡~~æƒ³å¿µå˜‰å®šè€è¡—çš„è‰å¤´é¥¼ğŸªå’ŒçŒªè¹„ğŸ·äº†ã€‚ å…ƒæ—¦çš„æ—¶å€™ï¼Œå¼€è½¦å»å—äº¬æ‰¾è€éƒ­è€ï¼Œåœ¨æ¼«å¤©é£é›ªé‡Œæ³¡æ¸©æ³‰ï¼Œè·¯å¥½æ»‘ï¼Œæˆ˜æˆ˜å…¢å…¢åœ°æ²¿ç€åˆ«äººçš„è½¨è¿¹å¼€ã€‚ è¿ä½ å¦ˆéƒ½è¯´æˆ‘æ¯”ä½ ä¸Šé•œå“ˆå“ˆå“ˆå“ˆï¼Œéš¾é“æˆ‘çœŸäººå¾ˆä¸‘å—ï¼Ÿå“ é¢†äº†ç»“å©šè¯çš„æˆ‘ä¿©ï¼Œåšä½œåœ°æ‰¾è§’åº¦ï¼Œå„ç§ç¾é¢œï¼Œå„ç§æ‹ã€‚ åœ¨ç±³å…°å¤§æ•™å ‚é—¨å‰ï¼Œè¢«æ„å¤§åˆ©éª—å­å¼ºè¡Œå¡äº†é¸½å­é£Ÿï¼Œç…§ç‰‡æ‹çš„ä¸é”™ï¼Œç„¶åå¾ˆåˆšåœ°ä»50æ¬§è¿˜ä»·åˆ°5æ¬§ã€‚ æ€»æ˜¯è¦æ±‚ä½ è§†é¢‘çš„æ—¶å€™äº²æˆ‘ï¼Œç„¶åæˆªå±æˆªå±ï¼Œå˜¿å˜¿ã€‚ å¸…æ°”çš„æˆ‘ä»¬ï¼Œåœ¨å¥¢åçš„å¼€ç½—äº”æ˜Ÿçº§é…’åº—ç”µæ¢¯é‡Œè‡ªæ‹ï¼Œç„¶åå»å°¼ç½—æ²³è¾¹å‹é©¬è·¯ã€‚ æœ‰ä¸€æ¬¡æ—…æ¸¸è¢«éª—ï¼Œè¢«éª—ä¸Šäº†éª†é©¼ï¼Œæé«˜çš„æˆ‘æ˜¯çœŸçš„æ…Œï¼Œéª†é©¼æ€ä¹ˆè¿™ä¹ˆé«˜ã€‚ æŠ é¼»å­”çš„ç¾ç…§æ€ä¹ˆèƒ½æ”¾è¿‡ï¼ é‚£æ¬¡æˆ‘ä»¬åœ¨å·´å˜å²›éª‘ç€å°æ‘©æ‰˜çªç„¶æš´é£é›¨ï¼Œæ’ç€è…°çš„ç¬¦çŒªçŒªï¼ŒèƒŒç€æ‘©æ´›å“¥çš„å°è…°åŒ…ï¼Œæ•´æ¡gaiä¸Šæœ€é“çš„ä»”ã€‚ æ˜æ˜ä¸èƒ½å–é…’ï¼Œè¿˜å¸¸å¸¸è¦é…’å–ï¼Œç„¶åå°è„¸ç»¯çº¢çš„çŒªçŒªï¼Œä½ çˆ¸çˆ¸çš„é…’ä»™åŸºå› å’‹æ²¡é—ä¼ å’§ã€‚ æ¯æ¬¡å‡ºæ¸¸éƒ½å½•ä¸€å †è§†é¢‘ç´ æï¼Œç„¶åä»æ¥ä¸å‰ªï¼Œæˆ‘ä»¬çœŸçš„æ˜¯è¶…çº§æ‡’å¤«å¦‡äº†ã€‚ é¢è¯•ç»“æŸçš„æˆ‘ä»¬çªç„¶çœ‹åˆ°äº†lineâ€™s friendsï¼Œæˆ‘åˆé”»ç‚¼èµ·äº†æ‹ç…§ï¼Œæˆ‘è®°å¾—è¿™å¼ ä½ è¿˜æ²¡å«Œå¼ƒæˆ‘ï¼Œå˜¿å˜¿ã€‚ ä½œä¸ºä¸€ä¸ªå¹´å°‘æ²¡å’‹åƒè¿‡ç¾é£Ÿçš„å°‘å¹´ï¼Œæ¯æ¬¡éƒ½è¢«ç¬¦çŒªçŒªå„ç§å¸¦ç€åƒå¥½åƒçš„ï¼Œè¿™ä¸ªå¥¶èŒ¶å†°ç²‰ï¼Œå¥½åƒåˆ°ç¿˜è„šã€‚ æœ€å–œæ¬¢ç¬¦çŒªçŒªçš„çŒªé¼»å­ğŸ½ï¼Œå……æ»¡å¼¹æ€§ï¼Œä¸€å¼ ä¸€ç¿•ï¼Œä¹è¶£æ— ç©·ï¼Œå˜¿å˜¿ã€‚å‹è½´ç™»åœºã€‚ å…¶å®æ¯ä¸€ä»¶äº‹æ¯ä¸€å¼ ç…§ç‰‡éƒ½æ˜¯æˆ‘ä»¬ç”Ÿæ´»å¾ˆå°çš„äº‹ï¼Œå¶å°”æ•´ç†ä¸€ä¸‹ï¼Œå›å¿†å›å¿†è¿‡å»çš„å¼€å¿ƒçš„æ—¥å­ï¼Œä¸å¼€å¿ƒçš„éƒ½çƒŸæ¶ˆäº‘æ•£ï¼Œæˆ‘ä»¬ä¹Ÿè¦å¥½å¥½çæƒœï¼Œå¤©å¤©å¼€å¿ƒï¼ğŸ†™ğŸ†™ğŸ†™æœ€åï¼Œç¥ç¬¦çŒªçŒªä¸ƒå¤•èŠ‚å¿«ä¹å“Ÿ~~~]]></content>
      <categories>
        <category>ç”Ÿæ´»</category>
      </categories>
      <tags>
        <tag>ç”Ÿæ´»</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ã€è®ºæ–‡ç¬”è®°ã€‘å¯»æ‰¾è®©æœºå™¨å¿ƒåŠ¨çš„â€œä¿¡å·â€]]></title>
    <url>%2F2019%2F08%2F03%2Fsignal%2F</url>
    <content type="text"><![CDATA[ä¸çŸ¥é“å¤§å®¶æœ‰æ²¡æœ‰è¿™æ ·çš„ç–‘æƒ‘ï¼Œåœ¨BERTæ¨ªç©ºå‡ºä¸–ä¹‹åï¼ŒNLPç®—æ³•å·¥ç¨‹å¸ˆçš„å·¥ä½œå¼€å§‹å˜å¾—è¶Šæ¥è¶Šæ— èŠäº†ï¼Œæƒ³è¦ç”¨Train-from-Scratchçš„æ¨¡å‹æˆ˜èƒœèŠéº»è¡—å®¶æ—ï¼Œå‡ ä¹å·²æ— å¯èƒ½ï¼Œå¾€å¾€ç»å°½è„‘æ±å¯èƒ½è¿˜ä¸å¦‚BERTåŠ ä¸€ä¸ªè¾“å‡ºå±‚Fine-Tuneã€‚é‚£ä¹ˆï¼Œæ—¢ç„¶è¿ç§»å­¦ä¹ çš„å¤§åŠ¿æ— æ³•é˜»æŒ¡ï¼Œä½œä¸ºç®—æ³•å·¥ç¨‹å¸ˆçš„æˆ‘ä»¬å¦‚ä½•èƒ½åœ¨BERTåæ—¶ä»£é‡Œæ‰¾åˆ°æ–°çš„ä¹è¶£å‘¢ï¼Ÿ ç“¦ç ¾æœ€è¿‘è¯»åˆ°äº†ä¸€ç¯‡ä¸é”™çš„åšå®¢ï¼šhttps://dawn.cs.stanford.edu/2019/03/22/glue/ï¼Œä»â€œä¿¡å·â€çš„è§’åº¦åˆ†æäº†åBERTæ—¶ä»£Fine-Tuneæ¨¡å‹æ—¶çš„å‘åŠ›ç‚¹ï¼Œé¢‡æœ‰å¯å‘ï¼Œæ•…æ­¤ç¿»è¯‘æ€»ç»“å¹¶åˆ†äº«ã€‚ Letâ€™s do itã€‚ æœºå™¨å­¦ä¹ çš„ä¸‰ä¸ªè¦ç´ å½“è§£å†³ä¸€ä¸ªNLPç›‘ç£å­¦ä¹ ä»»åŠ¡æ—¶ï¼Œæˆ‘ä»¬éœ€è¦è€ƒè™‘ä¸‰ä¸ªè¦ç´ ï¼š æ¨¡å‹ ç¡¬ä»¶ï¼Œä¹Ÿå°±æ˜¯è®¡ç®—èµ„æº æ•°æ® å…¶ä¸­ï¼Œç”±äºGoogleï¼ŒHuggingfaceç­‰å¤§ä½¬çš„å¼€æºè´¡çŒ®ï¼Œæƒ³æ„å»ºSOTAæ¨¡å‹å‡ ä¹åªéœ€è¦pip install xxxä¾¿å”¾æ‰‹å¯å¾—ï¼›åŠ ä¸Šå„ç§äº‘æœåŠ¡çš„è¯ç”Ÿï¼Œç®—åŠ›ä¹Ÿå¹¶ä¸æ˜¯å¾ˆå¤§çš„é—®é¢˜ï¼›ç„¶è€Œï¼ŒNLPé¢†åŸŸä¸­ï¼Œé«˜è´¨é‡çš„ç›‘ç£æ•°æ®ï¼Œä»ç„¶æ˜¯å¤„äºä¸€ç§ low-resource çš„çŠ¶æ€ï¼Œè¿™ä¹Ÿæˆä¸ºäº†å¤§å¤šæ•°åº”ç”¨åœºæ™¯çš„ç“¶é¢ˆï¼Œæ‰€ä»¥ï¼ŒNLPerä»¬å¼€å§‹å¯»æ‰¾ä¸€äº›è¿‚å›çš„æ–¹å¼â€œå›´é­æ•‘èµµâ€ï¼Œç»™ä»–ä»¬çš„æ¨¡å‹æ³¨å…¥ä¸€äº›é—´æ¥çš„ç›‘ç£ä¿¡å·ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬æƒ³è¦æ­å»ºä¸€å¥—ä»¥ç›‘ç£ä¿¡å·ä¸ºç‹çš„æ¡†æ¶ï¼Œä½¿å…¶èƒ½æ›´å¥½åœ°åˆ©ç”¨å¦‚ä»Šæ½œåœ¨çš„ä¸€äº›ç›‘ç£ä¿¡å·ï¼ŒåŒ…æ‹¬ï¼šä¼ ç»Ÿçš„ç›‘ç£ã€è¿ç§»å­¦ä¹ ã€å¤šä»»åŠ¡å­¦ä¹ ã€å¼±ç›‘ç£ç­‰ã€‚æˆ‘ä»¬ç§°ä¹‹ä¸ºMassive Multi-Task Learning (MMTL)ã€‚æˆ‘ä»¬ä»¥RTEï¼ˆRecognizing Textual Entailmentï¼‰ä»»åŠ¡ä¸ºä¾‹ï¼Œå±•ç¤ºäº†å¦‚ä½•é€šè¿‡é€æ¸å¢åŠ â€œä¿¡å·â€ï¼Œä¸€æ­¥æ­¥åœ°æé«˜æ¨¡å‹çš„è¡¨ç°ã€‚ RTEæ˜¯ä¸€ä¸ªç»å…¸çš„NLIä»»åŠ¡ï¼Œä¸€å…±æœ‰2.5kä¸ªè®­ç»ƒæ•°æ®ï¼Œä»»åŠ¡çš„ç›®æ ‡æ˜¯åˆ¤æ–­ç¬¬äºŒä¸ªå¥å­æ˜¯å¦ç”±ç¬¬ä¸€ä¸ªå¥å­æ¨æ–­è€Œæ¥ï¼Œæ•°æ®é‡ä¸å¤§å¾ˆç¬¦åˆæˆ‘ä»¬å®é™…çš„åº”ç”¨åœºæ™¯ã€‚ ç“¦ç ¾åœ¨è¿™ç”¨é«˜è€ƒä¸¾ä¾‹ï¼Œå¸¦ç€è¯»è€…walk throughä¸€éç»™æ¨¡å‹å¯»æ‰¾ä¿¡å·çš„è¿‡ç¨‹ï¼ åšä¿©ä¾‹é¢˜ï¼šä¼ ç»Ÿçš„ç›‘ç£ä¼ ç»Ÿç›‘ç£ä¿¡å·å½“ç„¶ä¸èƒ½è½ä¸‹ï¼Œè¿™å°±å¥½åƒé«˜è€ƒå‰å¾—åšäº›ä¾‹é¢˜ï¼Œåˆ·ç‚¹â€œäº”ä¸‰â€ä¸€æ ·ã€‚â€œè€å¸ˆï¼Œæˆ‘è¿˜èƒ½åˆ·ä¸¤æœ¬é»„å†ˆï¼â€ ä½¿ç”¨æ ‡å‡†çš„Bi-LSTMè®­ç»ƒï¼Œåœ¨è¯¥ä»»åŠ¡ä¸Šèƒ½è·å¾—57.4çš„å‡†ç¡®ç‡ï¼Œåªæ¯”éšæœºé«˜äº†ä¸€ç‚¹ï¼Œå³ä½¿æˆ‘ä»¬åŠ ä¸ŠElMo embeddingå’Œæ³¨æ„åŠ›æœºåˆ¶ï¼Œä¹Ÿåªèƒ½å°†åˆ†æ•°æé«˜åˆ°58.9ã€‚å¾ˆä¸å¹¸ï¼Œæ— è®ºæˆ‘ä»¬çš„æ¨¡å‹ç»“æ„æœ‰å¤šä¹ˆçš„fancyï¼Œä»2.5kç›‘ç£ä¿¡å·ä¸­ï¼ŒThatâ€™s all we can learnã€‚ æˆ‘ä»¬éœ€è¦æ›´å¤šä¿¡å·ï¼ğŸ’ª è¯»ä¸‡å·ä¹¦ï¼šè¿ç§»å­¦ä¹ è¿ç§»å­¦ä¹ å°±å¥½æ¯”è¯»ä¹¦ï¼Œä¸€ä¸ªåªè¯»è¿‡å‡ ç¯‡æ»¡åˆ†ä½œæ–‡çš„è€ƒç”Ÿæ˜¯å†™ä¸å‡ºã€Šæ¯ä¸­çª¥äººã€‹çš„ï¼Œè¦æƒ³â€œä½œæ–‡â€å†™çš„å¥½ï¼Œå…ˆå¾—å¤§é‡åœ°é˜…è¯»ï¼Œå³ä½¿ä¸ç”šç›¸å…³ï¼Œä¹Ÿæ˜¯ä¸€ç§ç§¯ç´¯ï¼Œåšç§¯æ‰èƒ½è–„å‘ã€‚ 2018å¹´è¢«ç§°ä¸ºâ€œNLPçš„ImageNetæ—¶åˆ»â€ï¼Œå› ä¸ºè¿™æ˜¯è¿ç§»å­¦ä¹ çœŸæ­£èµ·é£ï¼Œç»™NLPç•Œå¸¦æ¥é£é€Ÿæå‡çš„ä¸€å¹´ã€‚æˆ‘ä»¬æ‰€ç†ŸçŸ¥çš„ULMFitï¼ŒGPTä»¥åŠæ‹¥æœ‰ä¸‰äº¿å‚æ•°é‡çš„BERTåœ¨è¿™ä¸€å¹´å¤§æ”¾å¼‚å½©ã€‚è¿™äº›æ¨¡å‹éƒ½æ˜¯ç”¨ä¸€äº›è¯­è¨€æ¨¡å‹ä»»åŠ¡ï¼Œä½ä»¥å¤§é‡çš„æ•°æ®è®­ç»ƒè€Œæˆï¼Œå› æ­¤å­¦ä¹ è¿‡æ›´å¤šæ›´å¹¿æ³›çš„ä¿¡å·ï¼Œåœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­æ¸¸åˆƒæœ‰ä½™ï¼Œé²æ£’è€Œåˆæœ‰æ•ˆã€‚ åœ¨å®éªŒä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ç®€å•çš„BERTä¸ŠåŠ ä¸€ä¸ªçº¿æ€§å˜æ¢æ¥Fine-Tune RTEæ•°æ®é›†ï¼Œå¯¹æ¯”Baselineçš„58.9çš„å¾—åˆ†ï¼Œç«‹å³é£™å‡äº†17.6çš„ç‚¹ï¼Œæ¥åˆ°äº†76.5ã€‚è™½ç„¶RTEæ•°æ®é‡å¾ˆå°ï¼Œä½†ç”±äºæ¨¡å‹å·²ç»â€œçœ‹è¿‡å±±å’Œå¤§æµ·ï¼Œç©¿è¶Šè¿‡äººå±±äººæµ·â€ï¼Œç®€å•æ¨ç†ä»»åŠ¡å·²ç»æ˜¯ä¸€ç‚¹å°±é€šï¼Œä¸¾ä¸€åä¸‰äº†ã€‚ æˆ‘ä»¬åˆéœ€è¦æ›´å¤šä¿¡å·ï¼ğŸ’ª ä¹é—¨åŠŸè¯¾åŒæ­¥å­¦ï¼šå¤šä»»åŠ¡å­¦ä¹ ä½œä¸ºç›®æ ‡æ¸…åŒ—çš„é«˜è€ƒè€ƒç”Ÿï¼Œæ€èƒ½åç§‘ï¼Ÿæ›´ä½•å†µæ•°ç†åŒ–ä¸åˆ†å®¶ï¼Œæ”¿å²åœ°ç”Ÿç›¸äº’è£¨ç›Šã€‚åç§‘ï¼Ÿä¸ï¼Œä½ åªæ˜¯è¿‡æ‹Ÿåˆäº†åŒå­¦ã€‚ è¯­è¨€æ¨¡å‹å¯ä»¥æ•™ä¼šæ¨¡å‹å¾ˆå¤šä¸œè¥¿ï¼Œä½†æ•™ä¸ä¼šå®ƒæ‰€æœ‰ï¼Œæ¯”å¦‚åšRTEä»»åŠ¡ï¼Œæˆ‘ä»¬å¯ä»¥æ‰¾ä¸€äº›ç±»ä¼¼çš„NLIä»»åŠ¡ï¼Œç”¨multi-task learningçš„æ–¹å¼åŒæ­¥å»å­¦ä¹ ã€‚ Multi-Task Learningï¼ˆMTLï¼‰æ˜¯ä¸€ç§å…±äº«è¡¨è¾¾å±‚ï¼Œåˆ†ç¦»è¾“å‡ºå±‚ä»è€Œå»å­¦ä¹ ä¸åŒä»»åŠ¡ä¿¡å·çš„å­¦ä¹ æ–¹æ³•ã€‚å› ä¸ºæˆ‘ä»¬ç›¸ä¿¡ï¼Œé‡è¦çš„æ˜¯â€œä¿¡å·â€ï¼Œè€Œä¸æ˜¯æ¨¡å‹ç»“æ„ï¼Œæˆ‘ä»¬åœ¨BERTçš„åŸºç¡€ä¸Šä¸ºæ¯ä¸ªä»»åŠ¡åªæ·»åŠ ä¸€ä¸ªçº¿æ€§å˜æ¢ã€‚æˆ‘ä»¬ä½¿ç”¨MT-DNNä¸­çš„è®­ç»ƒæ–¹æ³•ï¼šæ¯ä¸ªbatchåªåŒ…å«ä¸€ä¸ªä»»åŠ¡ï¼Œå¤šä»»åŠ¡ä¹‹åå†å•ç‹¬åœ¨å„ä¸ªä»»åŠ¡ä¸ŠFine-Tuneä¸€ä¸‹ã€‚æœ€ç»ˆï¼ŒRTEå†æ¬¡æé«˜äº†6.9ä¸ªç™¾åˆ†ç‚¹ï¼Œè¾¾åˆ°äº†83.4çš„é«˜åˆ†ã€‚ æˆ‘ä»¬åˆåŒéœ€è¦æ›´å¤šä¿¡å·ï¼ğŸ’ª å¼€ä¸ªå°ç¶ï¼šå¤§é‡å¤šä»»åŠ¡å­¦ä¹ é«˜è€ƒè·¯é¥é¥ï¼Œä¸ä»…éœ€è¦ä½å¤´èµ¶è·¯ï¼Œä¹Ÿå¾—æŠ¬å¤´çœ‹çœ‹å¤©ï¼Œé—®è‡ªå·±ï¼šâ€œæˆ‘å“ªé‡Œè¿˜ä¸å¤Ÿä¼˜ç§€å‘¢ï¼Ÿâ€ æœ‰çš„æ”¾çŸ¢ï¼Œåšåˆ°å“ªé‡Œä¸ä¼šç‚¹å“ªé‡Œã€‚ æ—¥å¸¸å®éªŒæˆ–ä¸šåŠ¡ä¸­ï¼ŒError Analysisæ˜¯ä¸€ä¸ªå¾ˆé‡è¦çš„é’ˆå¯¹æ€§åœ°æé«˜æ¨¡å‹è¡¨ç°çš„æ–¹æ³•ï¼Œå‘ä¸ªæ¯”æ–¹ï¼šå½“ä½ å‘ç°Badcaseå¤§å¤šæ¥è‡ªäºå¯¹æ–‡æœ¬è¯­æ³•çš„ç†è§£é”™è¯¯ï¼Œå°±å¯ä»¥è€ƒè™‘å¢åŠ ä¸€ä¸ªå¥æ³•è§£æçš„è¾…åŠ©ä»»åŠ¡ï¼›åˆæˆ–æ˜¯ï¼Œå½“ä½ å‘ç°æ–‡æœ¬ä¸­å­˜åœ¨è¯¸å¤šæŒ‡ä»£ï¼Œåˆ™å¯å°è¯•å¢åŠ ä¸€ä¸ªæŒ‡ä»£æ¶ˆè§£çš„è¾…åŠ©ä»»åŠ¡ã€‚éœ€è¦çš„labelåˆ™å¯ä»¥ç”¨å¼€æºçš„ç³»ç»Ÿå»ç”Ÿæˆï¼Œä¸å¯é¿å…è¿™æ ·ä¼šå¼•å…¥ä¸€äº›é”™è¯¯ï¼Œä½†æ¨¡å‹ä¾ç„¶è¿˜æ˜¯å¯ä»¥åˆ©ç”¨è¿™äº›ä¿¡å·ï¼Œå»é’ˆå¯¹æ€§åœ°è¡¥å…¨ç¼ºå¤±çš„èƒ½åŠ›ã€‚ æˆ‘ä»¬åˆåŒå’éœ€è¦æ›´å¤šä¿¡å·ï¼ğŸ’ª æ•´ç†é”™é¢˜é›†ï¼šæ•°æ®åˆ‡åˆ†åœ¨å“ªé‡Œè·Œå€’ï¼Œå°±å¾—åœ¨å“ªé‡Œçˆ¬èµ·æ¥ã€‚åšäº†é”™é¢˜ä¸è¦ç´§ï¼Œå‡†å¤‡ä¸€æœ¬é”™é¢˜é›†ï¼Œè®°å½•ä¸‹æ¥ï¼Œåˆ†è€Œæ²»ä¹‹ï¼Œå°±æ€¼å®ƒï¼Œæ­»ç£•å®ƒã€‚ åœ¨å®éªŒä¸­ï¼Œæˆ‘ä»¬å‘ç°åœ¨RTEæ•°æ®é›†ä¸­ï¼Œæœ‰ä¸€äº›ç‰¹æ®Šçš„æ•°æ®å­é›†è¡¨ç°å¾ˆå·®ï¼Œæ¯”å¦‚ï¼šå½“æˆ‘ä»¬çš„æ¨¡å‹è·å¾—äº†83.4çš„å‡†ç¡®ç‡æ—¶ï¼Œå®ƒåœ¨æœ‰ç½•è§æ ‡ç‚¹çš„æ•°æ®ä¸­è¡¨ç°ä»…æœ‰76.7ï¼Œåœ¨ä»£è¯è¾ƒå¤šçš„æ•°æ®ä¸­ä»…æœ‰58.3ï¼Œè¿™æ„å‘³ç€ï¼Œè¿™äº›é—®é¢˜ç¡®å®éš¾ï¼Œå®¹æ˜“é”™ã€‚ é¢å¯¹ä¸Šè¿°çš„è¿™ä¸¤ç±»é—®é¢˜ï¼Œæˆ‘ä»¬ç”¨ä¸€äº›è§„åˆ™è¯†åˆ«å‡ºè¿™ç±»é—®é¢˜åï¼Œå•ç‹¬å¢åŠ ä¸€ä¸ªçº¿æ€§è¾“å‡ºå±‚å»è§£å†³å®ƒï¼Œè¡¨è¾¾å±‚ä»æ˜¯å…±äº«çš„ï¼Œä½¿å¾—ä¸€å°éƒ¨åˆ†ç½‘ç»œä¸“æ³¨äºè§£å†³è¿™ç±»é—®é¢˜ï¼Œä»è€Œæé«˜è¿™éƒ¨åˆ†æ•°æ®çš„è¡¨ç°ã€‚ç”¨äº†è¿™ä¸ªæ–¹æ³•ï¼Œ76.7æé«˜è‡³79.3ï¼Œ58.3æé«˜è‡³75.0ï¼Œæœ€ç»ˆæ€»å¾—åˆ†è¾¾åˆ°84.1ã€‚èµã€‚ æˆ‘ä»¬åˆåŒå’å•éœ€è¦æ›´å¤šä¿¡å·ï¼ğŸ’ª ä¹ä¹å½’ä¸€ï¼šEnsemblingé«˜è€ƒçš„è‡³é«˜å¢ƒç•Œï¼šäººæ ¼åˆ†è£‚å»é«˜è€ƒï¼Œä¹äººåŒè¡Œï¼Œä¸€äººé«˜ä¸­ã€‚åœ¨æ¯ä¸€é—¨ç§‘ç›®ä¸­ï¼Œæ´¾å‡ºä½ ä¸åŒçš„äººæ ¼å»é«˜è€ƒï¼Œè€ƒè¯­æ–‡æ—¶ï¼Œä½ æ˜¯å¼ çˆ±ç²ï¼›è€ƒæ•°å­¦æ—¶ï¼Œä½ æ˜¯é«˜æ–¯ï¼›è€ƒè‹±è¯­æ—¶ï¼Œä½ æ˜¯éŸ©æ¢…æ¢…ã€‚ Ensembleæ˜¯å¤§å®¶çš„è€æœ‹å‹äº†ï¼Œåœ¨åBERTæ—¶ä»£ï¼ŒEnsembleä¹Ÿå°¤å…¶é‡è¦ï¼Œæ¯”å¦‚Casedå’ŒUncasedçš„æ¨¡å‹ï¼Œå¸¸å¸¸å°±æ“…é•¿ä¸åŒçš„ä»»åŠ¡ï¼Œæ¯•ç«Ÿï¼Œä¸‰ä¸ªè‡­çš®åŒ ï¼Œé¡¶ä¸ªè¯¸è‘›äº®ï¼›ä¸‰ä¸ªè¯¸è‘›äº®ï¼Œé¡¶ä¹ä¸ªè‡­çš®åŒ ã€‚ æ‰“ä¸ªæ€»ç»“å…¶ä¸­æœ¬æ–‡çš„â€œå¹²è´§â€å¹¶æ²¡æœ‰é‚£ä¹ˆå¤šï¼Œæ›´å¤šåœ°æ˜¯ä¸€ç§æ€æƒ³å’Œæ–¹æ³•è®ºï¼Œå³ï¼šç›‘ç£ä¿¡å·è¦é‡è¦äºæ¨¡å‹ç»“æ„çš„äº›å¾®è°ƒæ•´ï¼ŒèƒŒåå…¶å®æ˜¯ç®—åŠ›ä¸ç®—æ³•çš„æƒè¡¡ã€‚ç“¦ç ¾è®¤ä¸ºï¼Œè¿™ä¸ªè§‚ç‚¹åœ¨bertæ—¶ä»£å°¤ä¸ºé€‚ç”¨ã€‚å½“ç„¶ï¼Œå¹¶ä¸æ˜¯å¦å®šç®—æ³•çš„ä½œç”¨ï¼Œè€Œæ˜¯è®¤ä¸ºç®—æ³•å’Œç®—åŠ›åº”å½“äº’ç›¸è¡¥å……ï¼Œè¿™é‡Œå¼•ç”¨XLNetä½œè€…æ¨æ¤éºŸçš„ä¸€æ®µé‡‡è®¿æ—¶è¯´çš„è¯ï¼š ä¾é ç®—åŠ›è§£å†³é—®é¢˜æ˜¯å½“å‰ç ”ç©¶ AI çš„ç‹é“ï¼šè®©è®¡ç®—æœºå»åšå®ƒçš„å¼ºé¡¹â€”â€”è®¡ç®—ï¼›å¦‚æœç®—åŠ›è§£å†³ä¸äº†çš„é—®é¢˜ï¼Œå†ç”¨ç®—æ³•å»åšã€‚ æŠŠç®—åŠ›æ¨åˆ°æè‡´çš„å¥½å¤„æ˜¯çŸ¥æ™“å½“å‰ç®—æ³•çš„è¾¹ç•Œï¼Œé¿å…åœ¨ç®—åŠ›å¯ä»¥è§£å†³çš„é—®é¢˜ä¸Šåšä¸€äº›ä¸å¿…è¦çš„ç®—æ³•åˆ›æ–°ï¼Œè®©å¤§å®¶å…³æ³¨æœ€é‡è¦çš„ç ”ç©¶é—®é¢˜ã€‚ä½†åŒæ—¶å¤§ç®—åŠ›å¸¦æ¥çš„å¼Šç«¯æ˜¯æå‡äº†ç ”ç©¶é—¨æ§›ï¼Œæ¯”å¦‚ä¸€èˆ¬çš„å­¦æ ¡å’Œå®éªŒå®¤å¯èƒ½æ²¡æœ‰èµ„æºåšé¢„è®­ç»ƒã€‚è¿™ä¸ªé—®é¢˜æˆ‘è§‰å¾—çŸ­æ—¶é—´å†…è¦é€šè¿‡ä¸åŒçš„åˆ†å·¥æ¥è§£å†³ï¼Œèµ„æºå¤šçš„ç ”ç©¶è€…åˆ©ç”¨èµ„æºåšå¤§ç®—åŠ›ç ”ç©¶ï¼Œèµ„æºå°‘çš„ç ”ç©¶è€…åšåŸºäºå°ç®—åŠ›çš„ç ”ç©¶ã€‚ è‡³æ­¤ï¼Œæˆ‘ä»¬çš„â€œä¿¡å·â€å¯»æ‰¾ä¹‹æ—…å‘Šä¸€æ®µè½å•¦ï¼Œä½†ç™¾å°ºç«¿å¤´æ›´è¿›ä¸€æ­¥ï¼Œå„ä½NLPerä»¬ç»§ç»­åŠ æ²¹ï¼Œå»å¯»æ‰¾é‚£äº›æµ©ç€šæ˜Ÿè¾°ä¸­æœªè¢«å‘ç°çš„â€œä¿¡å·â€å§ã€‚ PSï¼šå†™è¿™ç¯‡åšå®¢çœŸçš„æ˜¯æ¿€èµ·äº†ç“¦ç ¾æ— æ•°å…³äºé«˜è€ƒçš„å›å¿†ï¼Œå…¶å®ï¼Œå¾€å¾€æœºå™¨å­¦ä¹ ä¸­å¾ˆå¤šçš„ Intuition éƒ½æ˜¯å¯ä»¥ä»ç”Ÿæ´»ä¸­æ¥çš„ã€‚æœ€åï¼Œå¤§å®¶ä¸è¦å› ä¸ºæˆ‘è¿™ç¯‡é¸¡æ±¤å†™çš„å¤šå°±å–å…³å•Šã€‚Orzã€‚]]></content>
      <categories>
        <category>NLP</category>
        <category>è®ºæ–‡ç¬”è®°</category>
        <category>é¢„è®­ç»ƒ</category>
      </categories>
      <tags>
        <tag>å¤šä»»åŠ¡</tag>
        <tag>è¿ç§»å­¦ä¹ </tag>
        <tag>BERT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ã€åˆ†å¸ƒå¼è®­ç»ƒã€‘å•æœºå¤šå¡çš„æ­£ç¡®æ‰“å¼€æ–¹å¼ï¼ˆå››ï¼‰ï¼šHorovod]]></title>
    <url>%2F2019%2F07%2F26%2Fdistributed-training4%2F</url>
    <content type="text"><![CDATA[è®²å®Œäº†å•æœºå¤šå¡çš„åˆ†å¸ƒå¼è®­ç»ƒçš„ç†è®ºã€TensorFlowå’ŒPyTorchåˆ†åˆ«çš„å®ç°åï¼Œä»Šå¤©ç“¦ç ¾è®²ä¸€ä¸ªå¼ºå¤§çš„ç¬¬ä¸‰æ–¹æ’ä»¶ï¼šHorovodã€‚ Horovodæ˜¯Uberå¼€æºçš„è·¨å¹³å°çš„åˆ†å¸ƒå¼è®­ç»ƒå·¥å…·ï¼Œåå­—æ¥è‡ªäºä¿„å›½ä¼ ç»Ÿæ°‘é—´èˆè¹ˆï¼Œèˆè€…æ‰‹ç‰µæ‰‹å›´æˆä¸€ä¸ªåœˆè·³èˆï¼Œä¸Horovodè®¾å¤‡ä¹‹é—´çš„é€šä¿¡æ¨¡å¼å¾ˆåƒï¼Œæœ‰ä»¥ä¸‹å‡ ä¸ªç‰¹ç‚¹ï¼š å…¼å®¹TensorFlowã€Keraså’ŒPyTorchæœºå™¨å­¦ä¹ æ¡†æ¶ã€‚ ä½¿ç”¨Ring-AllReduceç®—æ³•ï¼Œå¯¹æ¯”Parameter Serverç®—æ³•ï¼Œæœ‰ç€æ— éœ€ç­‰å¾…ï¼Œè´Ÿè½½å‡è¡¡çš„ä¼˜ç‚¹ã€‚ å®ç°ç®€å•ï¼Œäº”åˆ†é’ŸåŒ…æ•™åŒ…ä¼šã€‚ï¼ˆåˆ’é‡ç‚¹ï¼‰ Uberå®˜æ–¹åœ¨gitä¸Šç»™äº†å¾ˆè¯¦ç»†çš„ä¾‹å­ï¼š https://github.com/horovod/horovod/tree/master/examplesï¼Œæ‰€ä»¥è¿™é‡Œåªç®€å•è®²ä¸€ä¸‹å¤§æ¦‚çš„ä½¿ç”¨æ–¹æ³•ï¼š TensorFlowä»¥TFçš„Custom Training Loop APIä¸ºä¾‹ï¼š12345678910111213141516171819202122232425import tensorflow as tfimport horovod.tensorflow as hvd# 1. åˆå§‹åŒ–horovodhvd.init()# 2. ç»™å½“å‰è¿›ç¨‹åˆ†é…å¯¹åº”çš„gpuï¼Œlocal_rank()è¿”å›çš„æ˜¯å½“å‰æ˜¯ç¬¬å‡ ä¸ªè¿›ç¨‹config = tf.ConfigProto()config.gpu_options.visible_device_list = str(hvd.local_rank())# 3. Scaleå­¦ä¹ ç‡ï¼Œå°è£…ä¼˜åŒ–å™¨opt = tf.train.AdagradOptimizer(0.01 * hvd.size())opt = hvd.DistributedOptimizer(opt)# 4. å®šä¹‰åˆå§‹åŒ–çš„æ—¶å€™å¹¿æ’­å‚æ•°çš„hookï¼Œè¿™ä¸ªæ˜¯ä¸ºäº†åœ¨ä¸€å¼€å§‹çš„æ—¶å€™åŒæ­¥å„ä¸ªgpuä¹‹é—´çš„å‚æ•°hooks = [hvd.BroadcastGlobalVariablesHook(0)]# æ­å»ºmodelï¼Œå®šä¹‰lossloss = ...train_op = opt.minimize(loss)# 5. åªä¿å­˜ä¸€ä»½ckptå°±è¡Œcheckpoint_dir = '/tmp/train_logs' if hvd.rank() == 0 else None# 7. ç”¨MonitoredTrainingSessionå®ç°åˆå§‹åŒ–ï¼Œè¯»å†™ckptwith tf.train.MonitoredTrainingSession(checkpoint_dir=checkpoint_dir, config=config, hooks=hooks) as mon_sess: while not mon_sess.should_stop(): # Perform synchronous training. mon_sess.run(train_op) å…·ä½“çš„ä»£ç çœ‹tensorflow_mnist.pyï¼šhttps://github.com/horovod/horovod/blob/master/examples/tensorflow_mnist.py å•æœºåŒå¡è®­ç»ƒè¾“å…¥ä»¥ä¸‹å‘½ä»¤ï¼š1CUDA_VISIBLE_DEVICES=6,7 horovodrun -np 2 -H localhost:2 python tensorflow_mnist.py è¿™é‡Œ -npæŒ‡çš„æ˜¯è¿›ç¨‹çš„æ•°é‡ã€‚ æ‰§è¡Œä¹‹åå¯ä»¥çœ‹åˆ°å¦‚ä¸‹çš„ç»“æœï¼Œå› ä¸ºå¤šçº¿ç¨‹ï¼Œæ¯ä¸ªstepéƒ½æ‰“å°äº†ä¸¤éã€‚ 1234567891011[1,0]&lt;stderr&gt;:INFO:tensorflow:loss = 0.13126025, step = 300 (0.191 sec)[1,1]&lt;stderr&gt;:INFO:tensorflow:loss = 0.01396352, step = 310 (0.177 sec)[1,0]&lt;stderr&gt;:INFO:tensorflow:loss = 0.063738815, step = 310 (0.182 sec)[1,1]&lt;stderr&gt;:INFO:tensorflow:loss = 0.044452004, step = 320 (0.215 sec)[1,0]&lt;stderr&gt;:INFO:tensorflow:loss = 0.028987963, step = 320 (0.212 sec)[1,0]&lt;stderr&gt;:INFO:tensorflow:loss = 0.09094897, step = 330 (0.206 sec)[1,1]&lt;stderr&gt;:INFO:tensorflow:loss = 0.11366991, step = 330 (0.210 sec)[1,0]&lt;stderr&gt;:INFO:tensorflow:loss = 0.08559138, step = 340 (0.200 sec)[1,1]&lt;stderr&gt;:INFO:tensorflow:loss = 0.037002128, step = 340 (0.201 sec)[1,0]&lt;stderr&gt;:INFO:tensorflow:loss = 0.15422738, step = 350 (0.181 sec)[1,1]&lt;stderr&gt;:INFO:tensorflow:loss = 0.06424393, step = 350 (0.179 sec) PyTorchTorchä¸‹ä¹Ÿæ˜¯ç±»ä¼¼çš„å¥—è·¯ï¼Œä½†æ˜¯ç”±äºPyTorchæœ¬èº«å•æœºå¤šå¡è®­ç»ƒå·²ç»å¤Ÿç®€å•äº†ï¼ŒAPIä¹Ÿç¨³å®šï¼Œæ‰€ä»¥ç¬”è€…ä¸€èˆ¬åšçš„æ—¶å€™å°±æ˜¯ç›´æ¥ç”¨Torchè‡ªå·±çš„DPå’ŒDDPäº†ã€‚ 1234567891011121314151617181920212223242526272829303132import torchimport horovod.torch as hvd# 1. åˆå§‹åŒ–horovodhvd.init()# 2. ç»™å½“å‰è¿›ç¨‹åˆ†é…å¯¹åº”çš„gpuï¼Œlocal_rank()è¿”å›çš„æ˜¯å½“å‰æ˜¯ç¬¬å‡ ä¸ªè¿›ç¨‹torch.cuda.set_device(hvd.local_rank())# Define dataset...train_dataset = ...# 3. ç”¨DistributedSamplerç»™å„ä¸ªworkeråˆ†æ•°æ®train_sampler = torch.utils.data.distributed.DistributedSampler( train_dataset, num_replicas=hvd.size(), rank=hvd.rank())train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=..., sampler=train_sampler)# Build model...model = ...model.cuda()# 4. å°è£…ä¼˜åŒ–å™¨optimizer = optim.SGD(model.parameters())optimizer = hvd.DistributedOptimizer(optimizer, named_parameters=model.named_parameters())# 5. åˆå§‹åŒ–çš„æ—¶å€™å¹¿æ’­å‚æ•°ï¼Œè¿™ä¸ªæ˜¯ä¸ºäº†åœ¨ä¸€å¼€å§‹çš„æ—¶å€™åŒæ­¥å„ä¸ªgpuä¹‹é—´çš„å‚æ•°hvd.broadcast_parameters(model.state_dict(), root_rank=0)# è®­ç»ƒfor epoch in range(100): for batch_idx, (data, target) in enumerate(train_loader): optimizer.zero_grad() output = model(data) loss = F.nll_loss(output, target) loss.backward() optimizer.step() if batch_idx % args.log_interval == 0: print('Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125;]\tLoss: &#123;&#125;'.format( epoch, batch_idx * len(data), len(train_sampler), loss.item())) é€Ÿåº¦ç“¦ç ¾è¿˜æ²¡æœ‰æ¥å¾—åŠåšä¸€ä¸ªå…¨é¢çš„Horovodã€tf.distributeå’Œ Torchçš„å•æœºå¤šå¡è®­ç»ƒé€Ÿåº¦çš„æ¨ªå‘å¯¹æ¯”ï¼Œä¸è¿‡å¤§å®¶å¯ä»¥å‚è€ƒè¿™ä¸¤ç¯‡ï¼š Horovod: fast and easy distributed deep learning in TensorFlow Goodbye Horovod, Hello CollectiveAllReduce æ€»ä½“è€Œè¨€ï¼Œç”¨äº†All-Reduceç®—æ³•çš„APIï¼Œé€Ÿåº¦åº”è¯¥éƒ½å·®ä¸å¤šï¼Œå¦‚æœä½ æ˜¯åœŸè±ªï¼Œæ‹¥æœ‰NVLINKï¼ˆå¡é—´é€šä¿¡æå¿«ï¼‰çš„è¯ï¼Œé‚£å¿˜äº†æˆ‘è¯´çš„è¿™å‡ ç¯‡â€œåºŸè¯â€å§æœ‹å‹ã€‚Orzã€‚ æ€»ç»“ç»ˆäºç»“æŸäº†å•æœºå¤šå¡ç³»åˆ—çš„æœ€åä¸€ç« ï¼Œç”±äºåšå®¢æœ¬èº«çš„é™åˆ¶ï¼Œç»™çš„ä¾‹å­æ•´ä½“è¿˜æ˜¯æ¯”è¾ƒç®€å•ï¼Œä»¥å…¥é—¨ä¸ºä¸»ï¼Œå¤§å®¶å…·ä½“ä½¿ç”¨çš„æ—¶å€™è‚¯å®šè¿˜æ˜¯ä¼šé‡åˆ°ä¸€äº›å‘ï¼Œè¿™é‡Œç“¦ç ¾æŠŠè¸©è¿‡çš„ä¸€äº›å‘å’Œè§£å†³åŠæ³•åˆ—ä¸¾åœ¨è¿™ï¼Œä»¥é¿å…å¤§å®¶ä»¥åé‡å¤è¸©å‘ï¼š tf.contrib.distributed.MirroredStrategy éœ€è¦optimizeræ”¯æŒmerge_callï¼ˆbertå®ç°çš„optimizeræ˜¯ç›´æ¥ä¿®æ”¹apply_gradientçš„ï¼Œæ‰€ä»¥ä¼šæŠ¥é”™ï¼‰ï¼Œè¿™ä¸ªæ—¶å€™å°±éœ€è¦æ­£ç¡®åœ°ä¿®æ”¹optimizeré‡Œçš„_apply_denseã€_apply_sparse(å‚è€ƒIssue 23986 å’Œ JayYip)ã€‚æˆ–è€…ç”¨horovodï¼Œå°±å¯ä»¥é¿å…è¿™ä¸ªé—®é¢˜ã€‚ Effective batch sizeï¼Œä¸åŒçš„å¤šå¡å·¥å…·å¯¹è¾“å…¥çš„batch sizeçš„æ“ä½œä¸ä¸€æ ·ï¼Œè¦ç¡®å®šæœ€åè¿›æ¨¡å‹çš„effective batch sizeæ‰æœ‰æ„ä¹‰ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œå¤šè¿›ç¨‹çš„batch sizeæŒ‡çš„æ˜¯æ¯å¼ å¡çš„batch sizeã€‚ Learning rate scaleï¼Œå­¦ä¹ ç‡è¦æ ¹æ®effective batch sizeè°ƒæ•´ã€‚ All-Reduceç”±äºæ˜¯å¤šè¿›ç¨‹çš„ï¼Œæ•°æ®æµå„è‡ªç‹¬ç«‹ï¼Œä¸ºäº†é˜²æ­¢åŒä¸€ä¸ªstepå¤šgpuçš„batché‡å ï¼Œæœ€å¥½çš„çš„åŠæ³•æ˜¯åœ¨æ¯ä¸ªè¿›ç¨‹é‡Œæ ¹æ®local_rankè®¾ç½®shardçš„æ•°æ®ï¼Œä¿è¯å„ä¸ªgpué‡‡æ ·çš„æ•°æ®ä¸é‡å ã€‚ ä¸ºäº†ä½¿ç”¨horovodï¼Œæ–°å»ºdocker containeræ—¶ï¼Œè¦åŠ â€“privilegedï¼Œå¦åˆ™ä¼šç–¯ç‹‚æŠ¥warningï¼Œè™½ç„¶æ²¡å½±å“ï¼Œä½†æ˜¯çœ‹ç€éš¾å—ã€‚ Pytorchçš„DPå¤šå¡è¦æ³¨æ„æœ€åä¸€ä¸ªbatchçš„batch sizeä¸èƒ½å°äºgpuçš„æ•°é‡ï¼Œå¦åˆ™ä¼šæŠ¥é”™ï¼Œæœ€ä¿é™©çš„åšæ³•æ˜¯drop_lastï¼Œæ‰”æ‰æœ€åçš„batchã€‚ å¹¶ä¸æ˜¯æ‰€æœ‰æƒ…å†µä¸‹All-Reduceéƒ½æ¯”PSå¥½ï¼Œæ¯”å¦‚å½“å¡é—´é€šä¿¡ç”¨çš„æ˜¯NVLinkçš„æ—¶å€™ï¼Œåœ¨gpuæ•°é‡ä¸å¤šçš„æƒ…å†µä¸‹ï¼Œæ•°æ®ä¼ è¾“çš„æ—¶é—´ä¸æ˜¯ç“¶é¢ˆï¼ŒAll-Reduceçš„æå‡å°±å‡ ä¹æ²¡æœ‰äº†ã€‚ DPå’ŒDDPæœ‰ä¸€ä¸ªåŒºåˆ«åœ¨äºBatchNormã€‚ DDPå°è£…modelåä¸èƒ½å†æ”¹åŠ¨modelã€‚ å¾…è¡¥å……ã€‚ã€‚ã€‚ Reference Horovodçš„å®˜æ–¹ç»™çš„ä¸€äº›ä¾‹å­ã€‚ Uberï¼šå¦‚ä½•ç”¨Horovodå®ç°bertçš„å•æœºå¤šå¡è®­ç»ƒ Goodbye Horovod, Hello CollectiveAllReduce Horovod: fast and easy distributed deep learning in TensorFlow]]></content>
      <categories>
        <category>è®­ç»ƒæ–¹æ³•</category>
        <category>åˆ†å¸ƒå¼è®­ç»ƒ</category>
      </categories>
      <tags>
        <tag>åˆ†å¸ƒå¼è®­ç»ƒ</tag>
        <tag>å¤šå¡è®­ç»ƒ</tag>
        <tag>Horovod</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ã€åˆ†å¸ƒå¼è®­ç»ƒã€‘å•æœºå¤šå¡çš„æ­£ç¡®æ‰“å¼€æ–¹å¼ï¼ˆä¸‰ï¼‰ï¼šPyTorch]]></title>
    <url>%2F2019%2F07%2F23%2Fdistributed-training3%2F</url>
    <content type="text"><![CDATA[æ‹–æ›´æ‹–æ›´äº†ï¼Œä»Šå¤©è®²ä¸€ä¸‹PyTorchä¸‹è¦å¦‚ä½•å•æœºå¤šå¡è®­ç»ƒã€‚ PyTorchçš„æ•°æ®å¹¶è¡Œç›¸å¯¹äºTensorFlowè€Œè¨€ï¼Œè¦ç®€å•çš„å¤šï¼Œä¸»è¦åˆ†æˆä¸¤ä¸ªAPIï¼š DataParallelï¼ˆDPï¼‰ï¼šParameter Serveræ¨¡å¼ï¼Œä¸€å¼ å¡ä½reducerï¼Œå®ç°ä¹Ÿè¶…çº§ç®€å•ï¼Œä¸€è¡Œä»£ç ã€‚ DistributedDataParallelï¼ˆDDPï¼‰ï¼šAll-Reduceæ¨¡å¼ï¼Œæœ¬æ„æ˜¯ç”¨æ¥åˆ†å¸ƒå¼è®­ç»ƒï¼Œä½†æ˜¯ä¹Ÿå¯ç”¨äºå•æœºå¤šå¡ã€‚ 1. DataParallelDataParallelæ˜¯åŸºäºParameter serverçš„ç®—æ³•ï¼Œè´Ÿè½½ä¸å‡è¡¡çš„é—®é¢˜æ¯”è¾ƒä¸¥é‡ï¼Œæœ‰æ—¶åœ¨æ¨¡å‹è¾ƒå¤§çš„æ—¶å€™ï¼ˆæ¯”å¦‚bert-largeï¼‰ï¼Œreducerçš„é‚£å¼ å¡ä¼šå¤šå‡º3-4gçš„æ˜¾å­˜å ç”¨ã€‚ å…ˆç®€å•å®šä¹‰ä¸€ä¸‹æ•°æ®æµå’Œæ¨¡å‹ã€‚ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import torchimport torch.nn as nnfrom torch.autograd import Variablefrom torch.utils.data import Dataset, DataLoaderimport osinput_size = 5output_size = 2batch_size = 30data_size = 30class RandomDataset(Dataset): def __init__(self, size, length): self.len = length self.data = torch.randn(length, size) def __getitem__(self, index): return self.data[index] def __len__(self): return self.lenrand_loader = DataLoader(dataset=RandomDataset(input_size, data_size), batch_size=batch_size, shuffle=True)class Model(nn.Module): # Our model def __init__(self, input_size, output_size): super(Model, self).__init__() self.fc = nn.Linear(input_size, output_size) def forward(self, input): output = self.fc(input) print(" In Model: input size", input.size(), "output size", output.size()) return outputmodel = Model(input_size, output_size)if torch.cuda.is_available(): model.cuda() if torch.cuda.device_count() &gt; 1: print("Let's use", torch.cuda.device_count(), "GPUs!") # å°±è¿™ä¸€è¡Œ model = nn.DataParallel(model) for data in rand_loader: if torch.cuda.is_available(): input_var = Variable(data.cuda()) else: input_var = Variable(data) output = model(input_var) print("Outside: input size", input_var.size(), "output_size", output.size()) 2. DDPå®˜æ–¹å»ºè®®ç”¨æ–°çš„DDPï¼Œé‡‡ç”¨all-reduceç®—æ³•ï¼Œæœ¬æ¥è®¾è®¡ä¸»è¦æ˜¯ä¸ºäº†å¤šæœºå¤šå¡ä½¿ç”¨ï¼Œä½†æ˜¯å•æœºä¸Šä¹Ÿèƒ½ç”¨ï¼Œä½¿ç”¨æ–¹æ³•å¦‚ä¸‹ï¼š åˆå§‹åŒ–ä½¿ç”¨ncclåç«¯1torch.distributed.init_process_group(backend=&quot;nccl&quot;) æ¨¡å‹å¹¶è¡ŒåŒ–1model=torch.nn.parallel.DistributedDataParallel(model) éœ€è¦æ³¨æ„çš„æ˜¯ï¼šDDPå¹¶ä¸ä¼šè‡ªåŠ¨shardæ•°æ® å¦‚æœè‡ªå·±å†™æ•°æ®æµï¼Œå¾—æ ¹æ®torch.distributed.get_rank()å»shardæ•°æ®ï¼Œè·å–è‡ªå·±åº”ç”¨çš„ä¸€ä»½ å¦‚æœç”¨Dataset APIï¼Œåˆ™éœ€è¦åœ¨å®šä¹‰Dataloaderçš„æ—¶å€™ç”¨DistributedSampler å»shardï¼š12sampler = DistributedSampler(dataset) # è¿™ä¸ªsamplerä¼šè‡ªåŠ¨åˆ†é…æ•°æ®åˆ°å„ä¸ªgpuä¸ŠDataLoader(dataset, batch_size=batch_size, sampler=sampler) å®Œæ•´çš„ä¾‹å­ï¼š12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import torchimport torch.nn as nnfrom torch.autograd import Variablefrom torch.utils.data import Dataset, DataLoaderimport osfrom torch.utils.data.distributed import DistributedSampler# 1) åˆå§‹åŒ–torch.distributed.init_process_group(backend="nccl")input_size = 5output_size = 2batch_size = 30data_size = 90# 2ï¼‰ é…ç½®æ¯ä¸ªè¿›ç¨‹çš„gpulocal_rank = torch.distributed.get_rank()torch.cuda.set_device(local_rank)device = torch.device("cuda", local_rank)class RandomDataset(Dataset): def __init__(self, size, length): self.len = length self.data = torch.randn(length, size).to('cuda') def __getitem__(self, index): return self.data[index] def __len__(self): return self.lendataset = RandomDataset(input_size, data_size)# 3ï¼‰ä½¿ç”¨DistributedSamplerrand_loader = DataLoader(dataset=dataset, batch_size=batch_size, sampler=DistributedSampler(dataset))class Model(nn.Module): def __init__(self, input_size, output_size): super(Model, self).__init__() self.fc = nn.Linear(input_size, output_size) def forward(self, input): output = self.fc(input) print(" In Model: input size", input.size(), "output size", output.size()) return output model = Model(input_size, output_size)# 4) å°è£…ä¹‹å‰è¦æŠŠæ¨¡å‹ç§»åˆ°å¯¹åº”çš„gpumodel.to(device) if torch.cuda.device_count() &gt; 1: print("Let's use", torch.cuda.device_count(), "GPUs!") # 5) å°è£… model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[local_rank], output_device=local_rank) for data in rand_loader: if torch.cuda.is_available(): input_var = data else: input_var = data output = model(input_var) print("Outside: input size", input_var.size(), "output_size", output.size()) éœ€è¦é€šè¿‡å‘½ä»¤è¡Œå¯åŠ¨ 1CUDA_VISIBLE_DEVICES=0,1 python -m torch.distributed.launch --nproc_per_node=2 torch_ddp.py ç»“æœï¼š12345678910Let&apos;s use 2 GPUs!Let&apos;s use 2 GPUs! In Model: input size torch.Size([30, 5]) output size torch.Size([30, 2])Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])Outside: input size torch.Size([15, 5]) output_size torch.Size([15, 2]) In Model: input size torch.Size([30, 5]) output size torch.Size([30, 2])Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2])Outside: input size torch.Size([15, 5]) output_size torch.Size([15, 2]) å¯ä»¥çœ‹åˆ°æœ‰ä¸¤ä¸ªè¿›ç¨‹ï¼Œlogæ‰“å°äº†ä¸¤é torch.distributed.launch ä¼šç»™æ¨¡å‹åˆ†é…ä¸€ä¸ªargs.local_rankçš„å‚æ•°ï¼Œä¹Ÿå¯ä»¥é€šè¿‡torch.distributed.get_rank()è·å–è¿›ç¨‹id]]></content>
      <categories>
        <category>è®­ç»ƒæ–¹æ³•</category>
        <category>åˆ†å¸ƒå¼è®­ç»ƒ</category>
      </categories>
      <tags>
        <tag>åˆ†å¸ƒå¼è®­ç»ƒ</tag>
        <tag>å¤šå¡è®­ç»ƒ</tag>
        <tag>PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ã€åˆ†å¸ƒå¼è®­ç»ƒã€‘å•æœºå¤šå¡çš„æ­£ç¡®æ‰“å¼€æ–¹å¼ï¼ˆäºŒï¼‰ï¼šTensorFlow]]></title>
    <url>%2F2019%2F07%2F14%2Fdistributed-training2%2F</url>
    <content type="text"><![CDATA[ç“¦ç ¾ä¸Šä¸€ç¯‡è®²äº†å•æœºå¤šå¡åˆ†å¸ƒå¼è®­ç»ƒçš„ä¸€äº›å…¥é—¨ä»‹ç»ï¼Œåé¢å‡ ç¯‡å‡†å¤‡ç»™å¤§å®¶è®²è®²TensorFlowã€PyTorchæ¡†æ¶ä¸‹è¦æ€ä¹ˆå®ç°å¤šå¡è®­ç»ƒã€‚ è¿™ä¸€ç¯‡å°±ä»‹ç»ä¸€ä¸‹TensorFlowä¸Šçš„åˆ†å¸ƒå¼è®­ç»ƒï¼Œå°½ç®¡ä»ä¼ ç»Ÿçš„Custom Training Loopsåˆ°Estimatorå†åˆ°Kerasï¼ŒTFçš„APIæ¢æ¥æ¢å»è®©äººçŒä¸åŠé˜²ã€åˆçˆ±åˆæ¨ï¼Œä½†æ˜¯ç”±äºç§ç§åŸå› ï¼ŒTensorFlowè¿˜æ˜¯ä¸šåŠ¡ä¸Šæœ€æˆç†Ÿçš„æ¡†æ¶ï¼Œæ‰€ä»¥Letâ€™sè¿˜æ˜¯do itã€‚ï¼ˆæ²¡çœ‹è¿‡ä¸Šä¸€ç¯‡çš„è¯»è€…å»ºè®®å…ˆçœ‹ä¸€ä¸‹åŸç†éƒ¨åˆ†ï¼šåˆ†å¸ƒå¼è®­ç»ƒçš„æ­£ç¡®æ‰“å¼€æ–¹å¼ï¼ˆä¸€ï¼‰ï¼šç†è®ºåŸºç¡€ï¼Œå› ä¸ºç®—æ³•çš„ç†è®ºç†è§£å¯¹äºåé¢APIçš„ç†è§£è¿˜æ˜¯å¾ˆé‡è¦çš„ã€‚ï¼‰ è¿™ç¯‡åšå®¢ä¸»è¦ä»‹ç»TensorFlowåœ¨1.13ç‰ˆæœ¬é‡Œå‘å¸ƒçš„tf.distribute APIï¼Œé›†æˆäº†ä¹‹å‰tf.contrib.distributeçš„å¾ˆå¤šåŠŸèƒ½ï¼Œå¹¶ä¸”å¤§å¤§çš„ç®€åŒ–äº†ä½¿ç”¨ã€‚å®˜æ–¹å¾ˆè‰¯å¿ƒçš„æ”¾äº†Google Colabï¼Œæƒ³è¦ä¸€æ­¥æ­¥æ‰§è¡Œçœ‹ç»“æœçš„è¯»è€…å¯ä»¥ç§»æ­¥å®˜æ–¹æ•™å­¦ã€‚ Overviewtf.distributeçš„æ ¸å¿ƒAPIæ˜¯tf.distribute.Strategyï¼Œå¯ä»¥ç®€ç®€å•å•å‡ è¡Œä»£ç å°±å®ç°å•æœºå¤šå¡ï¼Œå¤šæœºå¤šå¡ç­‰æƒ…å†µçš„åˆ†å¸ƒå¼è®­ç»ƒã€‚ä¸»è¦æœ‰è¿™å‡ ä¸ªä¼˜åŠ¿ï¼š ç®€å•æ˜“ç”¨ï¼Œå¼€ç®±å³ç”¨ï¼Œé«˜æ€§èƒ½ã€‚ ä¾¿äºå„ç§åˆ†å¸ƒå¼Strategyåˆ‡æ¢ã€‚ æ”¯æŒCustom Training Loopã€Estimatorã€Kerasã€‚ æ”¯æŒeager excutionã€‚ 123import osos.environ["CUDA_VISIBLE_DEVICES"]="0,1"import tensorflow as tf Strategyçš„ç±»åˆ«tf.distribute.Strategyè®¾è®¡çš„åˆè¡·æ˜¯èƒ½coverä¸åŒç»´åº¦çš„use casesï¼Œç›®å‰ä¸»è¦æœ‰å››ä¸ªStrategyï¼š MirroredStrategy CentralStorageStrategy MultiWorkerMirroredStrategy ParameterServerStrategy è¿˜æœ‰ä¸€äº›ç­–ç•¥ï¼Œä¾‹å¦‚å¼‚æ­¥è®­ç»ƒç­‰ç­‰ï¼Œåé¢ä¼šé€æ­¥æ”¯æŒã€‚ 1. MirroredStrategyé•œåƒç­–ç•¥ç”¨äºå•æœºå¤šå¡ æ•°æ®å¹¶è¡Œ åŒæ­¥æ›´æ–°çš„æƒ…å†µï¼Œåœ¨æ¯ä¸ªGPUä¸Šä¿å­˜ä¸€ä»½æ¨¡å‹å‰¯æœ¬ï¼Œæ¨¡å‹ä¸­çš„æ¯ä¸ªå˜é‡éƒ½é•œåƒåœ¨æ‰€æœ‰å‰¯æœ¬ä¸­ã€‚è¿™äº›å˜é‡ä¸€èµ·å½¢æˆä¸€ä¸ªåä¸ºMirroredVariableçš„æ¦‚å¿µå˜é‡ã€‚é€šè¿‡applyç›¸åŒçš„æ›´æ–°ï¼Œè¿™äº›å˜é‡ä¿æŒå½¼æ­¤åŒæ­¥ã€‚ é•œåƒç­–ç•¥ç”¨äº†é«˜æ•ˆçš„All-reduceç®—æ³•æ¥å®ç°è®¾å¤‡ä¹‹é—´å˜é‡çš„ä¼ é€’æ›´æ–°ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå®ƒä½¿ç”¨NVIDIA NCCLä½œä¸ºall-reduceå®ç°ã€‚ç”¨æˆ·è¿˜å¯ä»¥åœ¨å®˜æ–¹æä¾›çš„å…¶ä»–å‡ ä¸ªé€‰é¡¹ä¹‹é—´è¿›è¡Œé€‰æ‹©ã€‚ æœ€ç®€å•çš„åˆ›å»ºä¸€ä¸ªé•œåƒç­–ç•¥çš„æ–¹æ³•ï¼š 1mirrored_strategy = tf.distribute.MirroredStrategy() ä¹Ÿå¯ä»¥è‡ªå·±å®šä¹‰è¦ç”¨å“ªäº›devicesï¼š 1mirrored_strategy = tf.distribute.MirroredStrategy(devices=["/gpu:0", "/gpu:1"]) å®˜æ–¹ä¹Ÿæä¾›äº†å…¶ä»–çš„ä¸€äº›all-reduceå®ç°ï¼š tf.distribute.CrossDeviceOps tf.distribute.HierarchicalCopyAllReduce tf.distribute.ReductionToOneDevice tf.distribute.NcclAllReduce (default) 12mirrored_strategy = tf.distribute.MirroredStrategy( cross_device_ops=tf.distribute.HierarchicalCopyAllReduce()) 2. CentralStorageStrategyä¸­å¤®å­˜å‚¨ç­–ç•¥ï¼Œå‚æ•°è¢«ç»Ÿä¸€å­˜åœ¨CPUé‡Œï¼Œç„¶åå¤åˆ¶åˆ°æ‰€æœ‰GPUä¸Šï¼Œä¼˜ç‚¹æ˜¯GPUè´Ÿè½½å‡è¡¡äº†ï¼Œä½†æ˜¯ä¸€èˆ¬æƒ…å†µä¸‹CPUå’ŒGPUé€šä¿¡ä»£ä»·å¤§ï¼Œä¸å»ºè®®ä½¿ç”¨ã€‚ 1central_storage_strategy = tf.distribute.experimental.CentralStorageStrategy() 3. MultiWorkerMirroredStrategyè¿™ä¸ªAPIå’ŒMirroredStrategyå¾ˆç±»ä¼¼ï¼Œæ˜¯å…¶å¤šæœºå¤šå¡åˆ†å¸ƒå¼çš„ç‰ˆæœ¬ï¼Œç”±äºæˆ‘ä»¬ä¸»è¦æ˜¯ä»‹ç»å•æœºå¤šå¡ï¼Œè¿™é‡Œå°±ä¸å±•å¼€è®²äº†ã€‚ 1multiworker_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() 4. ParameterServerStrategyè¿™ä¸ªAPIå‘¢ï¼Œå°±æ˜¯è¢«å¤§å®¶æ™®éå«Œå¼ƒå³å°†æ·˜æ±°çš„PSç­–ç•¥ï¼Œæ…¢+è´Ÿè½½ä¸å‡è¡¡ã€‚ï¼ˆå’Œall-reduceçš„åŒºåˆ«ï¼Œè¯·çœ‹ä¸Šä¸€ç¯‡ï¼‰ 1ps_strategy = tf.distribute.experimental.ParameterServerStrategy() tf.distribute.Strategyåœ¨ä¸‰ç§APIä¸Šçš„ä½¿ç”¨ï¼šKerasã€Estimatorã€Custom Training Loops1. Keras123456789101112# è¿™é‡Œçš„Strategyå¯ä»¥æ¢æˆæƒ³ç”¨çš„ï¼Œå› ä¸ºå…¶ä»–ä¸‰ä¸ªè¿˜æ˜¯experimentalçš„çŠ¶æ€ï¼Œå»ºè®®ç”¨è¿™ä¸ªmirrored_strategy = tf.distribute.MirroredStrategy()with mirrored_strategy.scope(): # å®šä¹‰æ¨¡å‹çš„æ—¶å€™æ”¾åˆ°é•œåƒç­–ç•¥ç©ºé—´å°±è¡Œ model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))]) model.compile(loss='mse', optimizer='sgd')# æ‰‹åŠ¨åšä¸ªå‡æ•°æ®è·‘ä¸€ä¸‹dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(1000).batch(10)print('Train:')model.fit(dataset, epochs=2)print('\nEval:')model.evaluate(dataset) 2. Estimator1234567891011121314mirrored_strategy = tf.distribute.MirroredStrategy()# åœ¨configä¸­åŠ å…¥é•œåƒç­–ç•¥config = tf.estimator.RunConfig(train_distribute=mirrored_strategy, eval_distribute=mirrored_strategy)# æŠŠconfigåŠ åˆ°æ¨¡å‹é‡Œregressor = tf.estimator.LinearRegressor( feature_columns=[tf.feature_column.numeric_column('feats')], optimizer='SGD', config=config)def input_fn(): dataset = tf.data.Dataset.from_tensors((&#123;"feats":[1.]&#125;, [1.])) return dataset.repeat(1000).batch(10)# æ­£å¸¸è®­ç»ƒï¼Œæ­£å¸¸è¯„ä¼°regressor.train(input_fn=input_fn, steps=10)regressor.evaluate(input_fn=input_fn, steps=10) 3. Custom Training Loops123456789101112131415161718192021222324252627282930313233343536mirrored_strategy = tf.distribute.MirroredStrategy()# åœ¨mirrored_strategyç©ºé—´ä¸‹with mirrored_strategy.scope(): model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))]) optimizer = tf.train.GradientDescentOptimizer(0.1)# åœ¨mirrored_strategyç©ºé—´ä¸‹with mirrored_strategy.scope(): dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(1000).batch(global_batch_size) print(dataset) # è¿™é‡Œè¦åˆ†å‘ä¸€ä¸‹æ•°æ® dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset) print(dist_dataset.__dict__['_cloned_datasets'])def train_step(dist_inputs): def step_fn(inputs): features, labels = inputs logits = model(features) cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2( logits=logits, labels=labels) loss = tf.reduce_sum(cross_entropy) * (1.0 / global_batch_size) train_op = optimizer.minimize(loss) with tf.control_dependencies([train_op]): return tf.identity(loss) # è¿”å›æ‰€æœ‰gpuçš„loss per_replica_losses = mirrored_strategy.experimental_run_v2(step_fn, args=(dist_inputs,)) # reduce losså¹¶è¿”å› mean_loss = mirrored_strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None) return mean_losswith mirrored_strategy.scope(): input_iterator = dist_dataset.make_initializable_iterator() iterator_init = input_iterator.initialize() var_init = tf.global_variables_initializer() loss = train_step(input_iterator.get_next()) with tf.Session() as sess: sess.run([var_init, iterator_init]) for _ in range(2): print(sess.run(loss))]]></content>
      <categories>
        <category>è®­ç»ƒæ–¹æ³•</category>
        <category>åˆ†å¸ƒå¼è®­ç»ƒ</category>
      </categories>
      <tags>
        <tag>åˆ†å¸ƒå¼è®­ç»ƒ</tag>
        <tag>å¤šå¡è®­ç»ƒ</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ã€åˆ†å¸ƒå¼è®­ç»ƒã€‘å•æœºå¤šå¡çš„æ­£ç¡®æ‰“å¼€æ–¹å¼ï¼ˆä¸€ï¼‰ï¼šç†è®ºåŸºç¡€]]></title>
    <url>%2F2019%2F07%2F08%2Fdistributed-training%2F</url>
    <content type="text"><![CDATA[ç“¦ç ¾ç”±äºæœ€è¿‘bert-largeç”¨çš„æ¯”è¾ƒå¤šï¼Œè¸©äº†å¾ˆå¤šåˆ†å¸ƒå¼è®­ç»ƒçš„å‘ï¼ŒåŠ ä¸Šåœ¨TensorFlowå’ŒPyTorchä¹‹é—´æ›´æ¢ï¼Œç®—æ˜¯ç†Ÿæ‚‰äº†ä¸€ä¸‹å„ç±»æ¡†æ¶çš„åˆ†å¸ƒå¼è®­ç»ƒæ¥å£ï¼Œç”±äºé›†ä¸­åœ¨ä¸€èµ·è®²å¯èƒ½æ¯”è¾ƒä¹±ï¼Œç¬”è€…å‡†å¤‡åˆ†ä¸‰åˆ°å››ç¯‡æ¥è®²ä¸€ä¸‹æ·±åº¦å­¦ä¹ çš„åˆ†å¸ƒå¼è®­ç»ƒã€‚è¿™ä¸€ç¯‡å…ˆè®²ä¸€ä¸‹â€œåˆ†å¸ƒå¼è®­ç»ƒçš„ç±»å‹ä¸ç®—æ³•â€ã€‚ åˆ†å¸ƒå¼è®­ç»ƒçš„éœ€æ±‚å’Œé‡è¦æ€§ä¸éœ€è¦å¤šè¯´ï¼Œéšç€GPTã€BERTã€xlnetè¿™äº›é¢„è®­ç»ƒæ¨¡å‹çš„å‡ºç°ï¼Œæ™®é€šçš„16Gçš„æ˜¾å­˜å·²ç»ä¸è¶³ä»¥æ”¯æ’‘æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒçš„è¦æ±‚äº†ï¼Œè¿™æ—¶å€™å°±éœ€è¦ç”¨åˆ°åˆ†å¸ƒå¼è®­ç»ƒæ¥æé«˜æ•ˆç‡ã€‚ æ³¨æ„ï¼šè¿™ä¸ªç³»åˆ—ä¸»è¦ä»‹ç»å•æœºå¤šå¡çš„åˆ†å¸ƒå¼è®­ç»ƒæƒ…å†µï¼ˆè¿™ç§æƒ…å†µæ¯”è¾ƒå¸¸è§ï¼ŒåœŸè±ªå’Œå¤§ä½¬ä»¬è¯·å¿½ç•¥ï¼‰ã€‚ æ€»çš„æ¥è¯´ï¼Œåˆ†å¸ƒå¼è®­ç»ƒåˆ†ä¸ºè¿™å‡ ç±»ï¼š æŒ‰ç…§å¹¶è¡Œæ–¹å¼æ¥åˆ†ï¼šæ¨¡å‹å¹¶è¡Œ vs æ•°æ®å¹¶è¡Œ æŒ‰ç…§æ›´æ–°æ–¹å¼æ¥åˆ†ï¼šåŒæ­¥æ›´æ–° vs å¼‚æ­¥æ›´æ–° æŒ‰ç…§ç®—æ³•æ¥åˆ†ï¼šParameter Serverç®—æ³• vs AllReduceç®—æ³• æ¨¡å‹å¹¶è¡Œ vs æ•°æ®å¹¶è¡Œå‡è®¾æˆ‘ä»¬æœ‰nå¼ GPUï¼š æ¨¡å‹å¹¶è¡Œï¼šä¸åŒçš„GPUè¾“å…¥ç›¸åŒçš„æ•°æ®ï¼Œè¿è¡Œæ¨¡å‹çš„ä¸åŒéƒ¨åˆ†ï¼Œæ¯”å¦‚å¤šå±‚ç½‘ç»œçš„ä¸åŒå±‚ï¼› æ•°æ®å¹¶è¡Œï¼šä¸åŒçš„GPUè¾“å…¥ä¸åŒçš„æ•°æ®ï¼Œè¿è¡Œç›¸åŒçš„å®Œæ•´çš„æ¨¡å‹ã€‚ å½“æ¨¡å‹éå¸¸å¤§ï¼Œä¸€å¼ GPUå·²ç»å­˜ä¸ä¸‹çš„æ—¶å€™ï¼Œå¯ä»¥ä½¿ç”¨æ¨¡å‹å¹¶è¡Œï¼ŒæŠŠæ¨¡å‹çš„ä¸åŒéƒ¨åˆ†äº¤ç»™ä¸åŒçš„æœºå™¨è´Ÿè´£ï¼Œä½†æ˜¯è¿™æ ·ä¼šå¸¦æ¥å¾ˆå¤§çš„é€šä¿¡å¼€é”€ï¼Œè€Œä¸”æ¨¡å‹å¹¶è¡Œå„ä¸ªéƒ¨åˆ†å­˜åœ¨ä¸€å®šçš„ä¾èµ–ï¼Œè§„æ¨¡ä¼¸ç¼©æ€§å·®ã€‚å› æ­¤ï¼Œé€šå¸¸ä¸€å¼ å¯ä»¥æ”¾ä¸‹ä¸€ä¸ªæ¨¡å‹çš„æ—¶å€™ï¼Œä¼šé‡‡ç”¨æ•°æ®å¹¶è¡Œçš„æ–¹å¼ï¼Œå„éƒ¨åˆ†ç‹¬ç«‹ï¼Œä¼¸ç¼©æ€§å¥½ã€‚ åŒæ­¥æ›´æ–° vs å¼‚æ­¥æ›´æ–°å¯¹äºæ•°æ®å¹¶è¡Œæ¥è¯´ï¼Œç”±äºæ¯ä¸ªGPUè´Ÿè´£ä¸€éƒ¨åˆ†æ•°æ®ï¼Œé‚£å°±æ¶‰åŠåˆ°å¦‚æœæ›´æ–°å‚æ•°çš„é—®é¢˜ï¼Œåˆ†ä¸ºåŒæ­¥æ›´æ–°å’Œå¼‚æ­¥æ›´æ–°ä¸¤ç§æ–¹å¼ã€‚ åŒæ­¥æ›´æ–°ï¼šæ¯ä¸ªbatchæ‰€æœ‰GPUè®¡ç®—å®Œæˆåï¼Œå†ç»Ÿä¸€è®¡ç®—æ–°æƒå€¼ï¼Œç„¶åæ‰€æœ‰GPUåŒæ­¥æ–°å€¼åï¼Œå†è¿›è¡Œä¸‹ä¸€è½®è®¡ç®—ã€‚ å¼‚æ­¥æ›´æ–°ï¼šæ¯ä¸ªGPUè®¡ç®—å®Œæ¢¯åº¦åï¼Œæ— éœ€ç­‰å¾…å…¶ä»–æ›´æ–°ï¼Œç«‹å³æ›´æ–°æ•´ä½“æƒå€¼å¹¶åŒæ­¥ã€‚ åŒæ­¥æ›´æ–°æœ‰ç­‰å¾…ï¼Œé€Ÿåº¦å–å†³äºæœ€æ…¢çš„é‚£ä¸ªGPUï¼›å¼‚æ­¥æ›´æ–°æ²¡æœ‰ç­‰å¾…ï¼Œä½†æ˜¯æ¶‰åŠåˆ°æ›´å¤æ‚çš„æ¢¯åº¦è¿‡æ—¶ï¼Œlossä¸‹é™æŠ–åŠ¨å¤§çš„é—®é¢˜ã€‚æ‰€ä»¥å®è·µä¸­ï¼Œä¸€èˆ¬ä½¿ç”¨åŒæ­¥æ›´æ–°çš„æ–¹å¼ã€‚ Parameter Serverç®—æ³• vs Ring AllReduceç®—æ³•è¿™é‡Œè®²ä¸€ä¸‹å¸¸ç”¨çš„ä¸¤ç§å‚æ•°åŒæ­¥çš„ç®—æ³•ï¼šPS å’Œ Ring AllReduceã€‚ å‡è®¾æœ‰5å¼ GPUï¼š Parameter Serverï¼šGPU 0å°†æ•°æ®åˆ†æˆäº”ä»½åˆ†åˆ°å„ä¸ªå¡ä¸Šï¼Œæ¯å¼ å¡è´Ÿè´£è‡ªå·±çš„é‚£ä¸€ä»½mini-batchçš„è®­ç»ƒï¼Œå¾—åˆ°gradåï¼Œè¿”å›ç»™GPU 0ä¸Šåšç´¯ç§¯ï¼Œå¾—åˆ°æ›´æ–°çš„æƒé‡å‚æ•°åï¼Œå†åˆ†å‘ç»™å„ä¸ªå¡ã€‚ Ring AllReduceï¼š5å¼ ä»¥ç¯å½¢ç›¸è¿ï¼Œæ¯å¼ å¡éƒ½æœ‰å·¦æ‰‹å¡å’Œå³æ‰‹å¡ï¼Œä¸€ä¸ªè´Ÿè´£æ¥æ”¶ï¼Œä¸€ä¸ªè´Ÿè´£å‘é€ï¼Œå¾ªç¯4æ¬¡å®Œæˆæ¢¯åº¦ç´¯ç§¯ï¼Œå†å¾ªç¯4æ¬¡åšå‚æ•°åŒæ­¥ã€‚åˆ†ä¸ºScatter Reduceå’ŒAll Gatherä¸¤ä¸ªç¯èŠ‚ã€‚ Parameter Serverçš„æ€æƒ³å…¶å®æœ‰ç‚¹ç±»ä¼¼äºMapReduceï¼Œä»¥ä¸Šè®²åŒæ­¥å¼‚æ­¥çš„æ—¶å€™ï¼Œéƒ½æ˜¯ç”¨çš„è¿™ç§ç®—æ³•ï¼Œä½†æ˜¯å®ƒå­˜åœ¨ä¸¤ä¸ªç¼ºç‚¹ï¼š æ¯ä¸€è½®çš„è®­ç»ƒè¿­ä»£éƒ½éœ€è¦æ‰€æœ‰å¡éƒ½å°†æ•°æ®åŒæ­¥å®Œåšä¸€æ¬¡Reduceæ‰ç®—ç»“æŸï¼Œå¹¶è¡Œçš„å¡å¾ˆå¤šçš„æ—¶å€™ï¼Œæœ¨æ¡¶æ•ˆåº”å°±ä¼šå¾ˆä¸¥é‡ï¼Œè®¡ç®—æ•ˆç‡ä½ã€‚ æ‰€æœ‰çš„GPUå¡éœ€è¦å’ŒReducerè¿›è¡Œæ•°æ®ã€æ¢¯åº¦å’Œå‚æ•°çš„é€šä¿¡ï¼Œå½“æ¨¡å‹è¾ƒå¤§æˆ–è€…æ•°æ®è¾ƒå¤§çš„æ—¶å€™ï¼Œé€šä¿¡å¼€é”€å¾ˆå¤§ã€‚ å‡è®¾æœ‰Nä¸ªGPUï¼Œé€šä¿¡ä¸€æ¬¡å®Œæ•´çš„å‚æ•°æ‰€éœ€æ—¶é—´ä¸ºKï¼Œé‚£ä¹ˆä½¿ç”¨PSæ¶æ„ï¼ŒèŠ±è´¹çš„é€šä¿¡æˆæœ¬ä¸ºï¼š$$T = 2(N-1)K$$æ‰€ä»¥æˆ‘ä»¬äºŸéœ€ä¸€ç§æ–°çš„ç®—æ³•æ¥æé«˜æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒçš„å¹¶è¡Œæ•ˆç‡ã€‚ 2017 å¹´ Facebook å‘å¸ƒäº†ã€ŠAccurate, large minibatch SGD: Training ImageNet in 1 hour ã€‹éªŒè¯äº†å¤§æ•°æ®å¹¶è¡Œçš„é«˜æ•ˆæ€§ï¼ŒåŒå¹´ç™¾åº¦å‘è¡¨äº†ã€ŠBringing HPC techniques to deep learning ã€‹ï¼ŒéªŒè¯äº†å…¨æ–°çš„æ¢¯åº¦åŒæ­¥å’Œæƒå€¼æ›´æ–°ç®—æ³•çš„å¯è¡Œæ€§ï¼Œå¹¶æå‡ºäº†ä¸€ç§åˆ©ç”¨å¸¦å®½ä¼˜åŒ–ç¯è§£å†³é€šä¿¡é—®é¢˜çš„æ–¹æ³•â€”â€”Ring AllReduceã€‚ Parameter Serviceæœ€å¤§çš„é—®é¢˜å°±æ˜¯é€šä¿¡æˆæœ¬å’ŒGPUçš„æ•°é‡çº¿æ€§ç›¸å…³ã€‚è€ŒRing AllReduceçš„é€šä¿¡æˆæœ¬ä¸GPUæ•°é‡æ— å…³ã€‚Ring AllReduceåˆ†ä¸ºä¸¤ä¸ªæ­¥éª¤ï¼šScatter Reduceå’ŒAll Gatherã€‚ Scatter Reduceè¿‡ç¨‹ï¼šé¦–å…ˆï¼Œæˆ‘ä»¬å°†å‚æ•°åˆ†ä¸ºNä»½ï¼Œç›¸é‚»çš„GPUä¼ é€’ä¸åŒçš„å‚æ•°ï¼Œåœ¨ä¼ é€’N-1æ¬¡ä¹‹åï¼Œå¯ä»¥å¾—åˆ°æ¯ä¸€ä»½å‚æ•°çš„ç´¯ç§¯ï¼ˆåœ¨ä¸åŒçš„GPUä¸Šï¼‰ã€‚ All Gatherï¼šå¾—åˆ°æ¯ä¸€ä»½å‚æ•°çš„ç´¯ç§¯ä¹‹åï¼Œå†åšä¸€æ¬¡ä¼ é€’ï¼ŒåŒæ­¥åˆ°æ‰€æœ‰çš„GPUä¸Šã€‚ æ ¹æ®è¿™ä¸¤ä¸ªè¿‡ç¨‹ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—åˆ°All Reduceçš„é€šä¿¡æˆæœ¬ä¸ºï¼š$$T = 2(N-1)\frac{K}{N}$$å¯ä»¥çœ‹åˆ°é€šä¿¡æˆæœ¬Tä¸GPUæ•°é‡æ— å…³ã€‚ ç”±äºAll Reduceç®—æ³•åœ¨é€šä¿¡æˆæœ¬ä¸Šçš„ä¼˜åŠ¿ï¼Œç°åœ¨å‡ ä¸ªæ¡†æ¶åŸºæœ¬ä¸Šéƒ½å®ç°äº†å…¶å¯¹äºçš„å®˜æ–¹APIï¼Œåé¢å‡ ç¯‡ï¼Œç“¦ç ¾ä¼šè·Ÿå¤§å®¶ä¸€èµ·è¿‡ä¸€éTFï¼ŒTorchçš„åˆ†å¸ƒå¼è®­ç»ƒAPIå…·ä½“æ˜¯æ€ä¹ˆç”¨çš„ï¼Œæœ‰å“ªäº›å‘ã€‚ Reference æ˜¯æ—¶å€™æ”¾å¼ƒTensorflowï¼Œæ‹¥æŠ±Horovodäº† Tensorflowå•æœºå¤šå¡å®ç° Binging HPC Techniques to Deep Learning Training Neural Nets on Larger Batches: Practical Tips for 1-GPU, Multi-GPU &amp; Distributed setups]]></content>
      <categories>
        <category>è®­ç»ƒæ–¹æ³•</category>
        <category>åˆ†å¸ƒå¼è®­ç»ƒ</category>
      </categories>
      <tags>
        <tag>åˆ†å¸ƒå¼è®­ç»ƒ</tag>
        <tag>å¤šå¡è®­ç»ƒ</tag>
        <tag>horovod</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ã€ä¼˜åŒ–æŠ€å·§ã€‘æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆEMAï¼‰çš„åŸç†åŠPyTorchå®ç°]]></title>
    <url>%2F2019%2F06%2F01%2Fema%2F</url>
    <content type="text"><![CDATA[åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œç»å¸¸ä¼šä½¿ç”¨EMAï¼ˆæŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼‰è¿™ä¸ªæ–¹æ³•å¯¹æ¨¡å‹çš„å‚æ•°åšå¹³å‡ï¼Œä»¥æ±‚æé«˜æµ‹è¯•æŒ‡æ ‡å¹¶å¢åŠ æ¨¡å‹é²æ£’ã€‚ ä»Šå¤©ç“¦ç ¾å‡†å¤‡ä»‹ç»ä¸€ä¸‹EMAä»¥åŠå®ƒçš„Pytorchå®ç°ä»£ç ã€‚ EMAçš„å®šä¹‰æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆExponential Moving Averageï¼‰ä¹Ÿå«æƒé‡ç§»åŠ¨å¹³å‡ï¼ˆWeighted Moving Averageï¼‰ï¼Œæ˜¯ä¸€ç§ç»™äºˆè¿‘æœŸæ•°æ®æ›´é«˜æƒé‡çš„å¹³å‡æ–¹æ³•ã€‚ å‡è®¾æˆ‘ä»¬æœ‰nä¸ªæ•°æ®ï¼š$[\theta_1, \theta_2, â€¦, \theta_n]$ æ™®é€šçš„å¹³å‡æ•°ï¼š$\overline{v}=\frac{1}{n}\sum_{i=1}^n \theta_i$ EMAï¼š$v_t = \alpha\cdot v_{t-1} + (1-\alpha)\cdot \theta_t$ï¼Œå…¶ä¸­ï¼Œ$ v_t$è¡¨ç¤ºå‰$t$æ¡çš„å¹³å‡å€¼ ($v_0=0$)ï¼Œ$\alpha$ æ˜¯åŠ æƒæƒé‡å€¼ (ä¸€èˆ¬è®¾ä¸º0.9-0.999)ã€‚ Andrew Ngåœ¨Course 2 Improving Deep Neural Networksä¸­è®²åˆ°ï¼ŒEMAå¯ä»¥è¿‘ä¼¼çœ‹æˆè¿‡å»$1/(1-\alpha)$ä¸ªæ—¶åˆ»$v$å€¼çš„å¹³å‡ã€‚ æ™®é€šçš„è¿‡å»$n$æ—¶åˆ»çš„å¹³å‡æ˜¯è¿™æ ·çš„ï¼š$$v_t =\frac{(n-1)\cdot v_{t-1}+\theta_t}{n}$$ç±»æ¯”EMAï¼Œå¯ä»¥å‘ç°å½“$\alpha=\frac{n-1}{n}$æ—¶ï¼Œä¸¤å¼å½¢å¼ä¸Šç›¸ç­‰ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä¸¤ä¸ªå¹³å‡å¹¶ä¸æ˜¯ä¸¥æ ¼ç›¸ç­‰çš„ï¼Œè¿™é‡Œåªæ˜¯ä¸ºäº†å¸®åŠ©ç†è§£ã€‚ å®é™…ä¸Šï¼ŒEMAè®¡ç®—æ—¶ï¼Œè¿‡å»$1/(1-\alpha)$ä¸ªæ—¶åˆ»ä¹‹å‰çš„å¹³å‡ä¼šdecayåˆ° $\frac{1}{e}$ ï¼Œè¯æ˜å¦‚ä¸‹ã€‚ å¦‚æœå°†è¿™é‡Œçš„$v_t$å±•å¼€ï¼Œå¯ä»¥å¾—åˆ°ï¼š$$v_t = \alpha^n v_{t-n} + (1-\alpha)(\alpha^{n-1}\theta_{t-n+1}+ â€¦ +\alpha^0\theta_t)$$å…¶ä¸­ï¼Œ$n=\frac{1}{1-\alpha}$ï¼Œä»£å…¥å¯ä»¥å¾—åˆ°$\alpha^n=\alpha^{\frac{1}{1-\alpha}}\approx \frac{1}{e}$ã€‚ EMAçš„åå·®ä¿®æ­£å®é™…ä½¿ç”¨ä¸­ï¼Œå¦‚æœä»¤$v_0=0$ï¼Œæ­¥æ•°è¾ƒå°‘çš„æƒ…å†µä¸‹ï¼Œemaçš„è®¡ç®—ç»“æœä¼šæœ‰ä¸€å®šåå·®ã€‚ ç†æƒ³çš„å¹³å‡æ˜¯ç»¿è‰²çš„ï¼Œå› ä¸ºåˆå§‹å€¼ä¸º0ï¼Œæ‰€ä»¥å¾—åˆ°çš„æ˜¯ç´«è‰²çš„ã€‚ å› æ­¤å¯ä»¥åŠ ä¸€ä¸ªåå·®ä¿®æ­£ï¼ˆbias correctionï¼‰ã€‚$$v_t = \frac{v_t}{1-\alpha^t}$$æ˜¾ç„¶ï¼Œå½“tå¾ˆå¤§æ—¶ï¼Œä¿®æ­£è¿‘ä¼¼äº1ã€‚ åœ¨æ·±åº¦å­¦ä¹ çš„ä¼˜åŒ–ä¸­çš„EMAä¸Šé¢è®²çš„æ˜¯å¹¿ä¹‰çš„emaå®šä¹‰å’Œè®¡ç®—æ–¹æ³•ï¼Œç‰¹åˆ«çš„ï¼Œåœ¨æ·±åº¦å­¦ä¹ çš„ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œ$\theta_t$ æ˜¯tæ—¶åˆ»çš„æ¨¡å‹æƒé‡weightsï¼Œ$v_t$æ˜¯tæ—¶åˆ»çš„å½±å­æƒé‡ï¼ˆshadow weightsï¼‰ã€‚åœ¨æ¢¯åº¦ä¸‹é™çš„è¿‡ç¨‹ä¸­ï¼Œä¼šä¸€ç›´ç»´æŠ¤ç€è¿™ä¸ªå½±å­æƒé‡ï¼Œä½†æ˜¯è¿™ä¸ªå½±å­æƒé‡å¹¶ä¸ä¼šå‚ä¸è®­ç»ƒã€‚åŸºæœ¬çš„å‡è®¾æ˜¯ï¼Œæ¨¡å‹æƒé‡åœ¨æœ€åçš„næ­¥å†…ï¼Œä¼šåœ¨å®é™…çš„æœ€ä¼˜ç‚¹å¤„æŠ–åŠ¨ï¼Œæ‰€ä»¥æˆ‘ä»¬å–æœ€ånæ­¥çš„å¹³å‡ï¼Œèƒ½ä½¿å¾—æ¨¡å‹æ›´åŠ çš„é²æ£’ã€‚ EMAä¸ºä»€ä¹ˆæœ‰æ•ˆç½‘ä¸Šå¤§å¤šæ•°ä»‹ç»EMAçš„åšå®¢ï¼Œåœ¨ä»‹ç»å…¶ä¸ºä½•æœ‰æ•ˆçš„æ—¶å€™ï¼Œåªåšäº†ä¸€äº›ç›´è§‰ä¸Šçš„è§£é‡Šï¼Œç¼ºå°‘ä¸¥è°¨çš„æ¨ç†ï¼Œç“¦ç ¾åœ¨è¿™è¡¥å……ä¸€ä¸‹ï¼Œä¸å–œæ¬¢çœ‹å…¬å¼çš„è¯»è€…å¯ä»¥è·³è¿‡ã€‚ ä»¤ç¬¬næ—¶åˆ»çš„æ¨¡å‹æƒé‡ï¼ˆweightsï¼‰ä¸º$v_n$ï¼Œæ¢¯åº¦ä¸º$g_n$ï¼Œå¯å¾—ï¼š$$\begin{align}\theta_n &amp;= \theta_{n-1}-g_{n-1} \\&amp;=\theta_{n-2}-g_{n-1}-g_{n-2} \\&amp;= â€¦ \\&amp;= \theta_1-\sum_{i=1}^{n-1}g_i\end{align}$$ä»¤ç¬¬næ—¶åˆ»EMAçš„å½±å­æƒé‡ä¸º$v_n$ï¼Œå¯å¾—ï¼š$$\begin{align}v_n &amp;= \alpha v_{n-1}+(1-\alpha)\theta_n \\&amp;= \alpha (\alpha v_{n-2}+(1-\alpha)\theta_{n-1})+(1-\alpha)\theta_n \\&amp;= â€¦ \\&amp;= \alpha^n v_0+(1-\alpha)(\theta_n+\alpha\theta_{n-1}+\alpha^2\theta_{n-2}+â€¦+\alpha^{n-1}\theta_{1})\end{align}$$ ä»£å…¥ä¸Šé¢$\theta_n$çš„è¡¨è¾¾ï¼Œä»¤$v_0=\theta_1$å±•å¼€ä¸Šé¢çš„å…¬å¼ï¼Œå¯å¾—ï¼š$$\begin{align}v_n &amp;= \alpha^n v_0+(1-\alpha)(\theta_n+\alpha\theta_{n-1}+\alpha^2\theta_{n-2}+â€¦+\alpha^{n-1}\theta_{1})\\&amp;= \alpha^n v_0+(1-\alpha)(\theta_1-\sum_{i=1}^{n-1}g_i+\alpha(\theta_1-\sum_{i=1}^{n-2}g_i)+â€¦+ \alpha^{n-2}(\theta_1-\sum_{i=1}^{1}g_i)+\alpha^{n-1}\theta_{1})\\&amp;= \alpha^n v_0+(1-\alpha)(\frac{1-\alpha^n}{1-\alpha}\theta_1-\sum_{i=1}^{n-1}\frac{1-\alpha^{n-i}}{1-\alpha}g_i) \\&amp;= \alpha^n v_0+(1-\alpha^n)\theta_1 -\sum_{i=1}^{n-1}(1-\alpha^{n-i})g_i\\&amp;= \theta_1 -\sum_{i=1}^{n-1}(1-\alpha^{n-i})g_i\end{align}$$å¯¹æ¯”ä¸¤å¼ï¼š$$\begin{align}\theta_n &amp;= \theta_1-\sum_{i=1}^{n-1}g_i \\v_n &amp;= \theta_1 -\sum_{i=1}^{n-1}(1-\alpha^{n-i})g_i\end{align}$$EMAå¯¹ç¬¬iæ­¥çš„æ¢¯åº¦ä¸‹é™çš„æ­¥é•¿å¢åŠ äº†æƒé‡ç³»æ•°$1-\alpha^{n-i}â€‹$ï¼Œç›¸å½“äºåšäº†ä¸€ä¸ªlearning rate decayã€‚ PyTorchå®ç°ç“¦ç ¾çœ‹äº†ç½‘ä¸Šçš„ä¸€äº›å®ç°ï¼Œä½¿ç”¨èµ·æ¥éƒ½ä¸æ˜¯ç‰¹åˆ«æ–¹ä¾¿ï¼Œæ‰€ä»¥è‡ªå·±å†™äº†ä¸€ä¸ªã€‚ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class EMA(): def __init__(self, model, decay): self.model = model self.decay = decay self.shadow = &#123;&#125; self.backup = &#123;&#125; def register(self): for name, param in self.model.named_parameters(): if param.requires_grad: self.shadow[name] = param.data.clone() def update(self): for name, param in self.model.named_parameters(): if param.requires_grad: assert name in self.shadow new_average = (1.0 - self.decay) * param.data + self.decay * self.shadow[name] self.shadow[name] = new_average.clone() def apply_shadow(self): for name, param in self.model.named_parameters(): if param.requires_grad: assert name in self.shadow self.backup[name] = param.data param.data = self.shadow[name] def restore(self): for name, param in self.model.named_parameters(): if param.requires_grad: assert name in self.backup param.data = self.backup[name] self.backup = &#123;&#125;# åˆå§‹åŒ–ema = EMA(model, 0.999)ema.register()# è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ›´æ–°å®Œå‚æ•°åï¼ŒåŒæ­¥update shadow weightsdef train(): optimizer.step() ema.update()# evalå‰ï¼Œapply shadow weightsï¼›evalä¹‹åï¼Œæ¢å¤åŸæ¥æ¨¡å‹çš„å‚æ•°def evaluate(): ema.apply_shadow() # evaluate ema.restore() References æœºå™¨å­¦ä¹ æ¨¡å‹æ€§èƒ½æå‡æŠ€å·§ï¼šæŒ‡æ•°åŠ æƒå¹³å‡ï¼ˆEMAï¼‰ Exponential Weighted Average for Deep Neutal Networks]]></content>
      <categories>
        <category>Trick</category>
        <category>ä»£ç å®ç°</category>
      </categories>
      <tags>
        <tag>torch</tag>
        <tag>ema</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ã€è®ºæ–‡ç¬”è®°ã€‘MT-DNN]]></title>
    <url>%2F2019%2F05%2F23%2Fmt-dnn%2F</url>
    <content type="text"><![CDATA[æƒ³å†™è¿™ç¯‡è›®ä¹…çš„ï¼Œä½†ç”±äºä¹‹å‰ä¸€ç›´å¿™ç€æåˆ«çš„äº‹æƒ…ï¼ˆå¥½å§å°±æ˜¯æ‡’ï¼‰ï¼Œä¸€ç›´æ‹–ç€ã€‚åˆšå¥½æœ€è¿‘æœ‰ç”¨è¿™ä¸ªæ–¹é¢çš„éœ€æ±‚ï¼Œå°±åˆè¯»äº†ä¸€éè®ºæ–‡å’Œgithubä¸Šçš„ä¸€äº›å®ç°ã€‚ å¤§éƒ¨åˆ†çš„åšå®¢éƒ½åªæ˜¯ç²—ç•¥ç¿»è¯‘è®ºæ–‡ï¼Œç„¶è€Œå…‰çœ‹è®ºæ–‡ï¼Œå¾€å¾€ä¼šå¿½ç•¥ä¸€äº›å®ç°ç»†èŠ‚ï¼Œæ‰€ä»¥ç¬”è€…æœ€è¿‘åœ¨å°è¯•å°†è®ºæ–‡ç¬”è®°å’Œæºç è§£æç»“åˆèµ·æ¥ï¼Œå°±ä»è¿™ç¯‡MT-DNNå¼€å§‹å§ã€‚å¸Œæœ›å¤§å®¶å¤šå¤šææ„è§ã€‚ Paperï¼šMulti-Task Deep Neural Networks for Natural Language Understandingå…¶å®ä½œè€…ï¼ˆXiaodong Liuï¼‰æ—©åœ¨15å¹´å°±å†™è¿‡ä¸€ç¯‡Multi-taskç›¸å…³çš„è®ºæ–‡ï¼Œåªä¸è¿‡å½“æ—¶è¿˜æ²¡æœ‰bertè¿™æ ·ä¼˜ç§€çš„é¢„è®­ç»ƒè¡¨è¾¾å±‚ï¼Œåœ¨bertæ¨ªæ‰«å„å¤§æ¦œå•ä¹‹åï¼Œä½œè€…å°†ä¹‹å‰å¤šä»»åŠ¡çš„æ¦‚å¿µå’Œbertç›¸ç»“åˆï¼Œduang~å°±å‡ºäº†è¿™ä¸€ç¯‡åœ¨GLUEã€SNLIå’ŒSciTailåˆ›ä¸‹æ–°çš„SOTAçš„è®ºæ–‡ã€‚ Intuitionä¼šæ»‘é›ªçš„äººï¼Œå­¦æ»‘å†°è¦å®¹æ˜“çš„å¤šï¼ˆç¬”è€…è¯•è¿‡ï¼Œåè¿‡æ¥ä¸å¤§æˆç«‹ï¼Œæ‰‹åŠ¨ç‹—å¤´ï¼‰ã€‚æˆ‘è§‰å¾—ç±»æ¯”æˆä¹å¹´ä¹‰åŠ¡æ•™è‚²æ›´å¥½ï¼Œåé—¨åŠŸè¯¾åŒæ­¥å­¦ï¼Œæ•°å­¦æ˜¯ä½ å­¦ç‰©ç†çš„åŸºç¡€ï¼Œå†å²çŸ¥è¯†èƒ½æé«˜ä½ ä½œæ–‡çš„æ°´å¹³ï¼Œetcã€‚ Motivation ç›‘ç£å­¦ä¹ éœ€è¦å¤§é‡ç›‘ç£æ•°æ®ï¼Œä½†æ­£å¸¸æƒ…å†µä¸‹å’±éƒ½æ˜¯æ²¡æœ‰çš„ã€‚MTLï¼ˆmulti-task learningï¼‰å¯ä»¥æé«˜low-resourceä»»åŠ¡çš„è¡¨ç°ã€‚ MTLèƒ½èµ·åˆ°æ­£åˆ™çš„ä½œç”¨ï¼Œå‡è½»æ¨¡å‹å¯¹ç‰¹å®šä»»åŠ¡çš„è¿‡æ‹Ÿåˆã€‚ bertä¹‹ç±»çš„é¢„è®­ç»ƒæ¨¡å‹å……åˆ†åˆ©ç”¨äº†æ— ç›‘ç£æ•°æ®ã€‚MTLä½œä¸ºè¡¥å……ï¼Œè¿›ä¸€æ­¥åˆ©ç”¨äº†out-domainçš„ç›‘ç£æ•°æ®ã€‚ Modelæ¨¡å‹å¾ˆç®€å•ï¼Œçœ‹ä¸€ä¸‹è¿™ä¸ªå›¾ï¼š åº•å±‚shareäº†bertçš„è¡¨è¾¾å±‚ï¼Œè¾“å‡ºå±‚ä¸ºæ¯ä¸ªä»»åŠ¡è®¾è®¡äº†å„è‡ªçš„è¾“å…¥å½¢å¼å’Œlossè®¡ç®—æ–¹å¼ã€‚ ä»»åŠ¡å’Œlossè®¡ç®—ä»»åŠ¡åˆ†ç±»åŠæ•°æ®GLUE å•å¥åˆ†ç±»ï¼ˆSingle-Sentence Classificationï¼‰ï¼š CoLAï¼ˆCorpus of Linguistic Acceptabilityï¼‰ï¼šåˆ¤æ–­è‹±è¯­å¥å­æ˜¯å¦è¯­æ³•æ­£ç¡® SST-2ï¼ˆStanford Sentiment Treebankï¼‰ï¼šå½±è¯„æƒ…æ„Ÿåˆ†ç±» æ–‡æœ¬ç›¸ä¼¼åº¦ï¼ˆText Similarityï¼‰ï¼š STS-Bï¼ˆSemantic Textual Similarity Bench-markï¼‰ï¼šäººç±»æ ‡æ³¨çš„1-5çš„è¯­ä¹‰ç›¸ä¼¼åº¦æ•°æ®é›†ã€‚ å¯¹å¥åˆ†ç±»ï¼ˆPairwise Text Classificationï¼‰ï¼š RTEï¼ˆRecognizing Textual Entailmentï¼‰ï¼šentailment or not_entailment MNLIï¼ˆMulti-Genre Natural Language Inferenceï¼‰ï¼šentailmentï¼Œcontradictionï¼Œneural QQPï¼ˆQuora Question Pairsï¼‰ï¼šåˆ¤æ–­ä¸¤ä¸ªé—®é¢˜æ˜¯å¦é—®çš„æ˜¯åŒä¸€å†…å®¹ã€‚ MRPCï¼ˆMicrosoft Research Paraphrase Corpusï¼‰ï¼šåˆ¤æ–­æ˜¯å¦ä¸¤ä¸ªå¥å­æ˜¯è¯­ä¹‰ç›¸åŒçš„ã€‚ WNLIï¼ˆWinograd NLIï¼‰ï¼šWino-grad Schema datasetå¾—åˆ°çš„æ¨ç†ä»»åŠ¡ã€‚ ç›¸å…³æ€§æ’åºï¼ˆRelevance Rankingï¼‰ï¼š QNLIï¼ˆStanford Question Answeringï¼‰ï¼šé—®ç­”å¯¹æ•°æ®é›†ã€‚ Out-domain SNLIï¼ˆStanford Natural Language Inferenceï¼‰ï¼šFlickr30é‡Œäººå·¥æ ‡æ³¨äº†hypothesesçš„æ¨ç†æ•°æ®é›† SciTailï¼ˆScience Question Answering Textual Entailmentï¼‰ï¼šç§‘å­¦é—®é¢˜çš„æ¨ç†ï¼Œæ›´éš¾ã€‚ lossè®¡ç®—1. å•å¥åˆ†ç±»äº¤å‰ç†µï¼š$$P_r(c|X) = \text{softmax}(W^T_{SST}\cdot x)\\L(\Theta) = -\sum_c{\mathbb{I}(X, c) \log (P_r(c|X)) }$$ 2. æ–‡æœ¬ç›¸ä¼¼åº¦å‡æ–¹è¯¯å·®ï¼š$$\text{Sim}(X_1, X_2) = \text{sigmoid}(w^T_{STS}\cdot x)\\L(\Theta) = (y-\text{Sim}(X_1, X_2))^2$$ 3. å¯¹å¥åˆ†ç±»å‰é¢æ¯”è¾ƒå¸¸è§ï¼Œè¿™ä¸ªå¯¹å¥åˆ†ç±»ä½œè€…å¤„ç†çš„æ–¹å¼æ¯”è¾ƒç‰¹æ®Šï¼Œç”¨äº†18å¹´ä½œè€…è‡ªå·±æå‡ºçš„ä¸€ç§å« SANï¼ˆstochastic answer networkï¼‰çš„è¾“å‡ºå±‚æ„å»ºæ–¹å¼ï¼Œæ¨ç†è¿‡ç¨‹æœ‰ç‚¹ç¹çï¼Œç»™å¤§å®¶è´´ä¸ªå›¾ã€‚ æ³¨æ„å›¾ä¸­çš„$m$ï¼Œ$n$ éƒ½æ˜¯sequence lengthã€‚ æ€»ç»“èµ·æ¥å°±æ˜¯ï¼Œä½œè€…å¾—åˆ°queryå’Œpremiseåˆ†åˆ«çš„token-wiseçš„è¡¨è¾¾ä¹‹åï¼Œåœ¨ä»–ä»¬ä¸¤ä¸ªä¹‹é—´åšäº†ä¸€ä¸ªattentionï¼Œç„¶åå¼€è¾Ÿäº†ä¸€ä¸ªæ–°çš„çŠ¶æ€ç»´åº¦åšRNNï¼Œä»è€Œå¾—åˆ°å¤šæ¬¡é¢„æµ‹ç»“æœï¼Œå†åšå¹³å‡ï¼ˆç±»ä¼¼äºäººæ¨ç†æ—¶ï¼Œå¤šæ¬¡æ€è€ƒæ‰èƒ½å¾—åˆ°æœ€ç»ˆçš„åˆ¤æ–­ï¼‰ã€‚ä½œè€…åœ¨åé¢è¯æ˜äº† SAN ç»“æ„èƒ½å¸¦æ¥0.1%~0.5%çš„æå‡ã€‚ lossä¹Ÿæ˜¯äº¤å‰ç†µï¼š$$L(\Theta) = -\sum_c{\mathbb{I}(X, c) \log (P_r(c|X)) }$$ 4. ç›¸å…³æ€§æ’åºä½œè€…çš„è¿™ä¸ªlossè®¾è®¡è¿˜æ˜¯æŒºæœ‰æ„æ€çš„ï¼Œä¸ç”¨ç®€å•çš„äºŒåˆ†ç±»æ¥åšè¿™ä¸ªä»»åŠ¡ï¼Œè€Œæ˜¯ç”¨learning2rankçš„èŒƒå¼ï¼Œå¯¹äºæ¯ä¸ªquery $Q$ é‡‡æ · $N$ ä¸ªcandidatesï¼Œå…¶ä¸­$A^+$æ˜¯æ­£ç¡®ç­”æ¡ˆï¼Œå…¶ä»–çš„éƒ½æ˜¯æ˜¯é”™è¯¯ç­”æ¡ˆã€‚ è´Ÿå¯¹æ•°ä¼¼ç„¶ï¼š$$\text{Rel}(Q,A)=\text{sigmoid}(w^T_{QNLI} \cdot x)\\L(\Theta)=-\frac{\text{exp}(\text{Rel}(Q,A^+))}{\sum_{Aâ€™\in{\mathcal{A}}}\text{exp}(Rel(Q,Aâ€™))}$$ è®­ç»ƒè¿‡ç¨‹ è®­ç»ƒè¿‡ç¨‹å°±æ˜¯æŠŠæ‰€æœ‰æ•°æ®åˆå¹¶åœ¨ä¸€èµ·ï¼Œæ¯ä¸ªbatchåªæœ‰å•ä¸€ä»»åŠ¡çš„æ•°æ®ï¼ŒåŒæ—¶ä¼šå¸¦æœ‰ä¸€ä¸ªtask-typeçš„æ ‡å¿—ï¼Œè¿™æ ·æ¨¡å‹å°±çŸ¥é“è¯¥èµ°å“ªä¸€æ¡lossè®¡ç®—çš„è·¯å¾„ã€‚ è®ºæ–‡é‡Œå¹¶æ²¡æœ‰æåŠå¯¹äºå•ä¸ªä»»åŠ¡ï¼Œä¹‹åè¿˜è¦ä¸è¦å†å•ç‹¬Fine-tuneä¸€ä¸‹ï¼Œä¸è¿‡å‚è€ƒgithubçš„FAQï¼Œå†FTä¸€ä¸‹ï¼Œç»“æœä¼šæ›´å¥½ã€‚ å®éªŒå®ç°ç»†èŠ‚Optimizerï¼šAdamaxï¼ˆè¿™ä¸ªåœ°æ–¹è·Ÿbertä¸å¤ªä¸€æ ·ï¼‰lrï¼š5e-5batch sizeï¼š32max_num of epochsï¼š5SAN stepsï¼š5warm-upï¼š0.1clip gradient normï¼š1max seq lengthï¼š512 GLUEç»“æœ ä»Table 2 å¯ä»¥çœ‹å‡ºæ¥ï¼ŒMT-DNNåœ¨æ¯ä¸€é¡¹éƒ½è¶…è¿‡äº†bertï¼Œè€Œä¸”æ•°æ®è¶Šå°‘çš„ä»»åŠ¡ï¼Œæå‡è¶Šæ˜æ˜¾ï¼Œå¯¹äºQQPå’ŒMNLIæ¥è¯´ï¼Œæå‡å°±æ²¡é‚£ä¹ˆæ˜æ˜¾äº†ã€‚ Table 3ä¸­çš„ST-DNNåå­—å¾ˆç„ä¹ï¼Œå…¶å®ä¸bertä¸åŒçš„å°±æ˜¯ç”¨äº†æ–‡ä¸­çš„å¤æ‚äº†ä¸€ç‚¹çš„è¾“å‡ºæ¨¡å—å’Œlossçš„è®¾è®¡ï¼Œæ¯”å¦‚SANï¼Œlearning2rankè¿™äº›ï¼Œå•ç‹¬è®­ç»ƒå„ä¸ªä»»åŠ¡ã€‚å¯è§éƒ½æ˜¯æœ‰ä¸€å®šç¨‹åº¦çš„æå‡ã€‚æ‰€ä»¥MT-DNNç›¸å¯¹äºbertçš„æå‡å…¶å®æ¥è‡ªäº multi task å’Œ special output module ä¸¤ä¸ªéƒ¨åˆ†ã€‚ SNLI å’Œ SciTail ç»“æœ åœ¨å¾—åˆ°mult-taskè®­ç»ƒåçš„ckptåï¼Œç”¨è¿™ä¸ªweightså»fine tuneæ–°çš„ä»»åŠ¡ï¼Œç»“æœå’ŒGLUEçš„ä¿æŒä¸€è‡´ï¼Œéƒ½æœ‰æå‡ï¼Œä¸”å°æ•°æ®é›†ä»»åŠ¡çš„æå‡æ›´æ˜æ˜¾ã€‚ Domain é€‚åº”æ€§ç»“æœè¿™ä¸ªç»“æœæ¯”è¾ƒæœ‰è¶£ï¼Œç¬”è€…è®¤ä¸ºä¹Ÿæ˜¯æ¯”è¾ƒé‡è¦çš„ç‚¹ï¼ŒMT-DNNå¾—åˆ°çš„weightsç›¸å¯¹äºbertçš„weightsèƒ½åœ¨å¾ˆå°‘çš„æ•°æ®ä¸‹è¾¾åˆ°ä¸é”™çš„æ•ˆæœï¼Œä¸”æ•°æ®è¶Šå°‘ï¼Œç›¸å¯¹bertçš„æå‡å°±è¶Šå¤§ã€‚(ç”šè‡³23ä¸ªè®­ç»ƒæ ·æœ¬å°±èƒ½è¾¾åˆ°82.1%çš„å‡†ç¡®ç‡ï¼Œamazingå•Šã€‚) Conclusionæ‰“ä¸ªæ€»ç»“ï¼š MT-DNNçš„ä¼˜ç‚¹ï¼š æ•°æ®è¦æ±‚å°‘ æ³›åŒ–èƒ½åŠ›å¼ºï¼Œä¸å®¹æ˜“è¿‡æ‹Ÿåˆ MT-DNNçš„ç¼ºç‚¹ï¼š å®ç”¨æ€§ï¼šå®é™…åº”ç”¨ä¸­ä¹Ÿè®¸å¹¶ä¸èƒ½æ‰¾åˆ°ç‰¹åˆ«åˆé€‚çš„ï¼Œä¸”é«˜è´¨é‡çš„å¤šä»»åŠ¡ è®­ç»ƒæ…¢å•Šï¼ŒMT-DNNä½œè€…ç”¨äº†4å¼ v100ï¼Œæ™®é€šä¸šåŠ¡è¦ä¸èµ·è¿™ä¸ªæ¡ä»¶ï¼Œæ‰€ä»¥MT-DNNçš„å®šä½å…¶å®ç±»ä¼¼äºbertï¼Œè®­ç»ƒå¥½äº†å°±åˆ«ä¹±åŠ¨äº†ï¼Œå½“pretrain-modelç”¨ã€‚ ä½œè€…è®¤ä¸ºçš„Further work æ›´æ·±åº¦çš„share weights æ›´æœ‰æ•ˆçš„è®­ç»ƒæ–¹æ³• ç”¨æ›´å¯æ§çš„æ–¹å¼èå…¥æ–‡æœ¬çš„è¯­è¨€ç»“æ„ï¼ˆè¿™ç‚¹ä¸ªäººæ„Ÿè§‰ä¸é€‚ç”¨äºç°åœ¨å¤§åˆ€é˜”æ–§æé¢„è®­ç»ƒæ¨¡å‹çš„æƒ…å†µï¼‰ Codeæºç åœ°å€ï¼šhttps://github.com/namisan/mt-dnn é˜…è¯»æºç å‰ï¼Œæˆ‘ä¹ æƒ¯æ€è€ƒä¸€ä¸‹å¦‚æœæˆ‘è‡ªå·±å†™ï¼Œä¼šæ€ä¹ˆå†™ï¼š é¦–å…ˆå’±è‚¯å®šå¾—åˆ†ç±»ä¸€ä¸‹æ•°æ®ï¼Œæ¯ä¸€ç±»ä»»åŠ¡å¯¹åº”ä¸€ä¸ªæ•°æ®æµï¼Œä¸èƒ½æ¯ä¸ªä»»åŠ¡å†™ä¸€ä¸ªæ•°æ®æµï¼Œå¤ªç´¯äº†ã€‚ æ–°å»ºæ¨¡å‹çš„æ—¶å€™å¾—çŸ¥é“æœ‰å“ªäº›ä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡num_labelsæ˜¯å¤šå°‘ï¼Œè‡ªåŠ¨ç”Ÿæˆè¾“å‡ºå±‚é›†åˆå’Œä¸idçš„æ˜ å°„ï¼Œè®­ç»ƒå’Œæ¨ç†çš„æ—¶å€™æ ¹æ®ä»»åŠ¡idé€‰æ‹©è¾“å‡ºå±‚ã€‚ æ€ä¹ˆä¿è¯ä¸€ä¸ªepochç»“æŸï¼Œæ‰€æœ‰ä»»åŠ¡æ•°æ®é›†éƒ½ç”¨å®Œäº†å‘¢ï¼Ÿ max seq lengthã€learning rateã€batch sizeè¿™äº›è¶…å‚éœ€è¦æ ¹æ®ä»»åŠ¡å˜åŒ–å—ï¼Ÿä¸åŒä»»åŠ¡çš„losså¦‚ä½•scaleå‘¢ï¼Ÿ åŸºæœ¬ä¸Šï¼Œæƒ³åˆ°è¿™ï¼Œå¿ƒé‡Œéƒ½æœ‰ç‚¹æ•°äº†ï¼Œå¸¦ç€é—®é¢˜çœ‹æºç å®ç°ã€‚ å®˜æ–¹çš„æºç æ˜¯ç”¨PyTorchå®ç°çš„ï¼ŒåŒ…æ‹¬äº†MT-DNNçš„è®­ç»ƒï¼Œå’Œä¸€äº›ä¸‹æ¸¸ä»»åŠ¡çš„finetuneï¼ŒåŒæ—¶ä¹Ÿæä¾›äº†è®­ç»ƒå¥½çš„MT-DNNçš„æ¨¡å‹ã€‚æ ¸å¿ƒæ€æƒ³å’Œæ­¥éª¤å¦‚ä¸‹ï¼š prepro.pyï¼šé¢„å¤„ç†æ•°æ®ï¼Œå°†GLUEçš„å¤šä¸ªä»»åŠ¡åˆ†æˆå››ç±»ï¼Œç»Ÿä¸€å¤„ç†æˆ {&#39;uid&#39;: ids, &#39;label&#39;: label, &#39;token_id&#39;: input_ids, &#39;type_id&#39;: type_ids}çš„å½¢å¼ï¼Œæ–¹ä¾¿åé¢æ“ä½œã€‚ mt-dnn/batcher.pyï¼šè‡ªå®šä¹‰çš„data iteratorï¼Œå°†è¯»åˆ°çš„æ•°æ®å¤„ç†æˆTensorã€‚ mt-dnn/matcher.pyï¼šæ¨¡å‹ï¼Œä¹‹æ‰€ä»¥å«matcherï¼Œæ˜¯å› ä¸ºæ¨¡å‹æœ‰ä¸€ä¸ªModuleListï¼Œå­˜æ”¾äº†ä¸åŒä»»åŠ¡å¯¹åº”çš„è¾“å‡ºå±‚ï¼Œæ ¹æ®å½“å‰batchçš„ä»»åŠ¡ç±»å‹matchå¯¹åº”çš„è¾“å‡ºå±‚ã€‚ mt-dnn/model.pyï¼šè¿™é‡Œå‘½åæœ‰ç‚¹æ··æ·†ï¼Œå®é™…çš„æ¨¡å‹æ˜¯ä¸Šé¢çš„matcherï¼Œè¿™é‡Œåšäº†ä¸€äº›æ¨¡å‹å‰åçš„å¤„ç†å·¥ä½œï¼ˆemaï¼Œpredictï¼Œsaveæ¨¡å‹ä¹‹ç±»çš„ï¼‰ã€‚ é‡ç‚¹è®²ä¸€ä¸‹mt-dnn/batcher.pyå’Œmt-dnn/matcher.pyè¿™ä¸¤ä¸ªéƒ¨åˆ†ã€‚ batcher.py å¿½ç•¥ä½œè€…å¯¹äºbatchè¿™ä¸ªå•è¯ç–¯ç‹‚çš„æ‹¼å†™é”™è¯¯ï¼Œç›¸æ¯”äºå¸¸è§„å•ä»»åŠ¡çš„data_iteratorï¼Œè¿™ä¸ªç±»é™¤äº†iteræ•°æ®ï¼Œè¿˜è¦è¿”å›å…³äºè¿™ä¸ªä»»åŠ¡çš„å¿…è¦ä¿¡æ¯ï¼Œæ¯”å¦‚è¿™ä¸ªä»»åŠ¡çš„idï¼Œä»»åŠ¡çš„ç±»å‹ã€‚make_baches å®ç°æŠŠæ•°æ®æ‰“åŒ…æˆbatchï¼Œresetç”¨æ¥åœ¨æ¯ä¸ªepochä¹‹åé‡æ–°shuffleå¹¶æ‰“åŒ…æˆbatchã€‚ matcher.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051class SANBertNetwork(nn.Module): def __init__(self, opt, bert_config=None): super(SANBertNetwork, self).__init__() self.dropout_list = [] self.bert_config = BertConfig.from_dict(opt) self.bert = BertModel(self.bert_config) if opt['update_bert_opt'] &gt; 0: for p in self.bert.parameters(): p.requires_grad = False mem_size = self.bert_config.hidden_size self.decoder_opt = opt['answer_opt'] # æ„å»ºModuleListï¼Œindexä¸ºtask_id self.scoring_list = nn.ModuleList() labels = [int(ls) for ls in opt['label_size'].split(',')] task_dropout_p = opt['tasks_dropout_p'] self.bert_pooler = None for task, lab in enumerate(labels): decoder_opt = self.decoder_opt[task] # ä¸åŒä»»åŠ¡dropoutä¹Ÿä¸ä¸€æ · dropout = DropoutWrapper(task_dropout_p[task], opt['vb_dropout']) self.dropout_list.append(dropout) if decoder_opt == 1: out_proj = SANClassifier(mem_size, mem_size, lab, opt, prefix='answer', dropout=dropout) self.scoring_list.append(out_proj) else: out_proj = nn.Linear(self.bert_config.hidden_size, lab) self.scoring_list.append(out_proj) self.opt = opt self._my_init() self.set_embed(opt) def forward(self, input_ids, token_type_ids, attention_mask, premise_mask=None, hyp_mask=None, task_id=0): all_encoder_layers, pooled_output = self.bert(input_ids, token_type_ids, attention_mask) sequence_output = all_encoder_layers[-1] if self.bert_pooler is not None: pooled_output = self.bert_pooler(sequence_output) decoder_opt = self.decoder_opt[task_id] if decoder_opt == 1: max_query = hyp_mask.size(1) assert max_query &gt; 0 assert premise_mask is not None assert hyp_mask is not None hyp_mem = sequence_output[:,:max_query,:] # é€šè¿‡ä»»åŠ¡idï¼Œç´¢å¼•åˆ°å¯¹åº”çš„è¾“å‡ºå±‚ï¼Œæå®šã€‚ logits = self.scoring_list[task_id](sequence_output, hyp_mem, premise_mask, hyp_mask) else: pooled_output = self.dropout_list[task_id](pooled_output) logits = self.scoring_list[task_id](pooled_output) return logits è¿™é‡Œç¬”è€…åˆ é™¤äº†å…¶ä»–å‡½æ•°ï¼Œåªä¿ç•™äº†__init__å’Œforwardï¼Œæ­£å¦‚æˆ‘ä»¬çœ‹æºç ä¹‹å‰çŒœæƒ³çš„ï¼Œä½œè€…å°±æ˜¯é€šè¿‡æ„å»ºä¸€ä¸ªModuleListï¼Œæ ¹æ®å„ä¸ªä»»åŠ¡çš„ç±»å‹ã€labelæ•°ç­‰ä¿¡æ¯appendè¾“å‡ºå±‚ï¼Œindexå³ä»»åŠ¡idã€‚]]></content>
      <categories>
        <category>NLP</category>
        <category>è®ºæ–‡ç¬”è®°</category>
        <category>å¤šä»»åŠ¡</category>
      </categories>
      <tags>
        <tag>bert</tag>
        <tag>å¤šä»»åŠ¡</tag>
        <tag>è¿ç§»å­¦ä¹ </tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ã€è®ºæ–‡ç¬”è®°ã€‘Attention is all you need]]></title>
    <url>%2F2019%2F01%2F27%2Ftransfomer%2F</url>
    <content type="text"><![CDATA[ä»Šå¹´çš„NLPç•Œè¢«BERTæ•´çš„æ˜æ˜ç™½ç™½ï¼Œå…¶ä¸­çš„åŸºæœ¬ç»“æ„ Transformer ä¸€å®šè¦äº†è§£ä¸€ä¸‹ã€‚ Abstractï¼šä¸€èˆ¬æ¥è¯´ï¼Œé‡è¦çš„sequence transductionæ¨¡å‹éƒ½æ˜¯åŸºäºåŒ…å«encoderï¼Œdecoderçš„å¤æ‚çš„rnnå’Œcnnçš„ã€‚æœ€å¥½çš„æ¨¡å‹æ˜¯é€šè¿‡ä¸€ä¸ªattentionæœºåˆ¶æ¥è¿æ¥encoderï¼Œdecoderã€‚æ¯”è¾ƒæ™®é€šï¼æˆ‘ä»¬æå‡ºä¸€ä¸ªåªé attentionçš„ã€‚å«Transformerï¼Œè·Ÿcnnï¼Œrnnå®Œå…¨æ²¡å…³ç³»ï¼Œå¾ˆç‚«é…·ã€‚ åœ¨ä¸¤ä¸ªç¿»è¯‘ä»»åŠ¡å®éªŒè¯æ˜ï¼šæˆ‘ä»¬çš„æ¨¡å‹åˆå¿«åˆå¥½ï¼ï¼ï¼ é«˜äº†2ä¸ªBLEUï¼› ç”¨8ä¸ªgpuè®­ç»ƒ3.5å¤©ï¼Œç»“æœç›´æ¥è¶…è¿‡äº†å½“å‰çš„SOTAã€‚ æˆ‘ä»¬è¿˜è¯æ˜ï¼ŒTransformeræ³›åŒ–æ€§èƒ½è´¼å¥½ï¼Œåœ¨parsingä¸Šå¤§å°æ•°æ®éƒ½æ¯”åˆ«çš„å¥½ ã€‚ åˆ’é‡ç‚¹ï¼šåªé Attentionã€‚ 1. IntroductionRNNï¼ŒLSTMï¼ŒGRUåœ¨ç¿»è¯‘å’Œ LMï¼ˆlanguage modelï¼‰é¢†åŸŸæäº†å¾ˆå¤šSOTAï¼Œå¾ˆå¤šç ”ç©¶èŠ±äº†å¾ˆå¤šå¿ƒæ€åœ¨push Encoder-Decoderå’ŒRecurrent Language Modelçš„è¾¹ç•Œã€‚ å¯æ˜¯ï¼ŒRNNçš„å¤©æ€§å†³å®šäº†è®­ç»ƒçš„æ—¶å€™å¹¶è¡Œæ€§å·®ã€‚å°¤å…¶å¯¹é•¿çš„sequenceï¼Œå†…å­˜é™åˆ¶å½±å“batch examplesäº†ã€‚å¾ˆçƒ¦ï¼æœ‰ä¸€äº›é€šè¿‡åˆ†è§£trickså’Œæ¡ä»¶è®¡ç®—æ¥æé«˜efficiencyçš„related workï¼Œåè€…ä¹Ÿæé«˜performanceã€‚ä½†æ˜¯é—®é¢˜ä¾ç„¶å­˜åœ¨ã€‚ Attentionæœºåˆ¶ç°åœ¨å‡ ä¹å¹²å•¥éƒ½å¿…é¡»äº†ï¼Œå¯ä»¥ä¸é¡¾è¾“å…¥è¾“å‡ºçš„distanceåœ°å»modelä¾èµ–ã€‚ä½†æ˜¯ï¼Œé™¤äº†æå°‘casesï¼ŒattentionåŸºæœ¬éƒ½å’Œrnnç»‘å®šåœ¨äº†ä¸€èµ·ï¼Œå¾ˆä¸æœºæ™ºï¼ Soï¼Œå’±æå‡ºä¸€ç§ä¸é rnnï¼Œåªé attentionçš„ï¼ï¼ï¼å¹¶è¡Œæ€§åˆšåˆšçš„ï¼Œ8ä¸ªp100èŠ±äº†12 hourså°±è¾¾åˆ°ç¿»è¯‘çš„new sotaã€‚ 2. Backgroundä¸€äº›ç›¸å…³çš„ç ”ç©¶éƒ½ç”¨äº†cnnæ¥å‡å°‘sequenceè®¡ç®—ã€‚ è¿™äº›æ¨¡å‹é‡Œoperationsçš„æ•°é‡éšç€è¾“å…¥è¾“å‡ºè·ç¦»çš„çº¿æ€§ï¼ˆconvS2Sï¼‰æˆ–æ˜¯æŒ‡æ•°çº§ï¼ˆByteNetï¼‰åœ°å¢é•¿ã€‚ä½¿å¾—å¾ˆéš¾å­¦ä¹ åˆ°è¾ƒè¿œçš„dependencyã€‚ åœ¨Transformeré‡Œï¼Œè¿™æ˜¯ä¸€ä¸ªå¸¸æ•°çº§çš„æ“ä½œï¼Œè™½ç„¶æ˜¯ä»¥ç‰ºç‰²ä¸€å®šç²¾åº¦ä¸ºä»£ä»·ï¼Œä½†æ˜¯æˆ‘ä»¬ç”¨Multi-Head Attentionæ¥æŠµæ¶ˆäº†ï¼Œæ•ˆæœå¾ˆå¥½ï¼ Self-attentionï¼Œé€šè¿‡relateä¸€ä¸ªsingle sequenceçš„ä¸åŒä½ç½®æ¥è®¡ç®—seqçš„è¡¨å¾ã€‚æˆåŠŸç”¨åœ¨é˜…è¯»ç†è§£ï¼Œsummarizationç­‰ç­‰ã€‚ åŸºäºattentionçš„end2endçš„memoryç½‘ç»œåœ¨å¾ˆå¤šç®€å•QAå’ŒLMé—®é¢˜ä¸Šæ¯”seq-aligned rnnï¼ˆå°±æ˜¯s2så§ï¼‰è¦å¥½ã€‚ä½†æ˜¯å•Šï¼ŒTransformeræ˜¯ç¬¬ä¸€ä¸ªåªé self-attentionæ¥è®¡ç®—è¡¨å¾çš„ã€‚ä¸‹é¢ä»‹ç»ä¸€æ³¢Transformerï¼ 3. Model Architecture å…¶å®ï¼Œè€ç“¦çœ‹åˆ°è¿™ä¸ªæ¨¡å‹çš„ä¸€ç¬é—´ï¼Œå¿ƒæƒ…æ˜¯å¤æ‚ï¼Œçœ‹ç€å¥½ç®€å•ï¼Œå¯æ˜¯å’‹å’Œä»¥å‰é‚£ç§æœ‰ä¸ªåºåˆ—ï¼Œæ¸…æ¸…æ¥šæ¥šå†™ç€$(x_1, x_2, â€¦, x_n)$ä»€ä¹ˆçš„æ¨¡å‹ä¸å¤ªä¸€æ ·ï¼Ÿä¸æ…Œï¼Œè€ç“¦æ¥ç›˜ä¸€ç›˜ã€‚ 3.1 Encoder and Decoder StacksEncoderï¼šEncoderæ˜¯ç”±N=6ç›¸åŒçš„å±‚ç»„æˆçš„æ ˆï¼Œæ¯å±‚éƒ½æœ‰ä¸¤ä¸ªå­å±‚ã€‚ç¬¬ä¸€å­å±‚æ˜¯ä¸€ä¸ªmulti-head self-attention mechanismï¼ˆå¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼‰ï¼Œç¬¬äºŒå­å±‚æ˜¯ä¸€ä¸ªposition-wiseçš„å…¨è¿æ¥å‰é¦ˆå±‚ã€‚æ¯ä¸ªå­å±‚åé¢éƒ½åŠ äº†ä¸€ä¸ªresidual connectionï¼ˆå†—ä½™è¿æ¥ï¼‰+layer normalizationï¼ˆå±‚æ­£åˆ™ï¼‰ï¼Œä¹Ÿå°±æ˜¯è¯´æ¯ä¸ªå­å±‚çš„è¾“å‡ºéƒ½æ˜¯ $\text{LayerNorm}(x+\text{Sublayer}(x))$ ã€‚ä¸ºäº†æ–¹ä¾¿åšåŠ è¿ç®—ï¼Œæ‰€æœ‰å­å±‚çš„è¾“å‡ºç»´åº¦éƒ½æ˜¯$d_{model}=512$ã€‚ Decoderï¼šDecoderä¹Ÿæ˜¯N=6å±‚çš„ã€‚ä¸»è¦ä¸¤ä¸ªåŒºåˆ«ï¼š å¢åŠ äº†ä¸€ä¸ªå­å±‚ï¼Œå°†encoderçš„è¾“å‡ºå½“åšè¾“å…¥ã€‚ ä¿®æ”¹äº†decoderæ ˆçš„è‡ªæ³¨æ„åŠ›è‡ªå±‚ï¼Œæ¥é˜²æ­¢ä½ç½®ä»¬å»å…³æ³¨åç»­çš„ä½ç½®ã€‚maskingç»“åˆoutputçš„embeddingéƒ½å³ç§»äº†ä¸€ä½è¿™ä¸ªäº‹å®ï¼Œä¿è¯äº†ä½ç½®içš„é¢„æµ‹åªä¾èµ–äºæ¯”iå°çš„å·²çŸ¥ä½ç½®ã€‚ 3.2 Attentionæ—¢ç„¶æ–‡ç« åå­—å«Attention is all you needï¼Œattentionçš„ç»“æ„å½“ç„¶æ˜¯å…¶ä¸­çš„é‡ä¸­ä¹‹é‡ï¼Œç†è§£äº†Attentionå°±å‡ ä¹ç†è§£äº†æ–‡ç« çš„ä¸€å¤§åŠã€‚ 3.2.1 Basic Attentioné¦–å…ˆï¼Œå¾—çŸ¥é“å•¥æ˜¯attentionã€‚14å¹´Sutskeverå¤§ç¥ç¥­å‡ºseq2seqä¹‹åï¼Œç´§è·Ÿç€Bahdanauå’ŒLuongå°±å‘äº†ä¸¤ç¯‡attentionç”¨åœ¨seq2seqçš„è®ºæ–‡ï¼Œåå­—ä¹Ÿå¥½è®°ï¼Œä¸€ä¸ªå«Bahdanau attentionï¼Œä¸€ä¸ªå«Luong attentionã€‚è¿™é‡Œä»¥Bahdanau Attentionä¸ºä¾‹ï¼Œè®²ä¸€è®²è®¡ç®—attentionçš„åŸºæœ¬å¥—è·¯ã€‚ å…¶å®ï¼Œattentionæœºåˆ¶å’Œæ™®é€šseq2seqçš„ä¸åŒå°±æ˜¯ï¼Œè¦è®¡ç®—å‡ºä¸€ä¸ªåŒ…å«ä¸Šä¸‹æ–‡ä¿¡æ¯çš„context vectorä½œä¸ºdecoderæ¯ä¸ªä½ç½®çš„è¾“å…¥ã€‚è®¡ç®—attentionæ—¶ï¼Œä¸€èˆ¬æœ‰Query(Q)ï¼ŒKey(K)ï¼ŒValue(V) ä¸‰ä¸ªè¾“å…¥ã€‚åœ¨ä¸Šé¢è¿™å¼ å›¾ä¸Šï¼ŒQå°±æ˜¯ $(s_0, s_1, â€¦ s_m)$ ï¼ŒKå’ŒVå°±æ˜¯$(h_0, h_1, â€¦, h_n)$ã€‚attentionæœºåˆ¶ä¸€èˆ¬çš„å¥—è·¯å°±æ˜¯ï¼Œç”¨Qå’ŒKå…ˆç®—å‡ºä¸€ä¸ªæƒé‡çš„å‘é‡ï¼Œå†ç”¨è¿™ä¸ªæƒé‡çš„å‘é‡å»element-wiseåœ°ä¹˜ä¸ŠVï¼Œå°±èƒ½å¾—åˆ°Context Vectorï¼š$$ConVec(Q, K, V) = softmax(score(Q, K))V$$ 3.2.2 Scaled Dot-Product Attentionæ˜ç™½äº†attentionçš„å¥—è·¯ï¼Œæˆ‘ä»¬æ¥çœ‹çœ‹è®ºæ–‡é‡Œçš„attentionæ˜¯ä»€ä¹ˆæ¥å¤´ï¼Œå…ˆçœ‹çœ‹åŸæ–‡ä¸­è¿™å¼ æ— æ¯”æ¸…æ™°ï¼ˆä½†æ˜¯çœ‹èµ·æ¥æœ‰ç‚¹å”¬äººï¼‰çš„å›¾ã€‚ è¿™åˆæ˜¯Scaled Dot-Productåˆæ˜¯Multi-Headçš„ï¼Œä¸€å¼€å§‹ç€å®è®©è€ç“¦æ„Ÿåˆ°æœ‰ç‚¹æ…Œï¼Œåæ¥ä»”ç»†ä¸€çœ‹ï¼Œå…¶å®æŒºç®€å•ã€‚ çœ‹è¿‡Luongé‚£ç¯‡attentionçš„æ–‡ç« çš„äººéƒ½çŸ¥é“ï¼Œscoreä¸€èˆ¬æœ‰ä¸‰ç§ç®—æ³•ï¼š$$score(h_t, \overline{h}_s) =\begin{cases}h_t^{\top}\overline{h}_s &amp;dot \\h_t^{\top}W_a\overline{h}_s &amp;general\\v_a^{\top}tanh(W_a[h_t;\overline{h}_s]) &amp;concat\end{cases}$$å…¶å®æ–‡ç« é‡Œç”¨çš„å°±æ˜¯ç¬¬ä¸€ç§ï¼Œå› ä¸ºæ€§ä»·æ¯”é«˜ï¼ˆæ•ˆæœè¿˜ä¸é”™é€Ÿåº¦å¿«ï¼‰ï¼Œä½†æ˜¯æœ‰ä¸ªç¼ºç‚¹å½“Qï¼ŒKçš„ç»´åº¦æ¯”è¾ƒå¤§çš„æ—¶å€™ï¼Œå®¹æ˜“è¿›åˆ°softmaxçš„é¥±å’ŒåŒºï¼Œä½œè€…å°±scaleäº†ä¸€ä¸‹ï¼ˆé™¤ä»¥$\sqrt{d_k}$ï¼‰ï¼Œè§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼Œè¿™ä¸ªå°±æ˜¯æ‰€è°“çš„Scaled Dot-Product Attentionã€‚ç²—æš´æœ‰æ•ˆã€‚$$Attention(Q, K, V) = softmax(\frac{QK^{\top}}{\sqrt{d_k}})V$$åŸºæœ¬ä¸Šå°±å®Œäº‹äº†ã€‚ è€ç“¦åœ¨çœ‹è®ºæ–‡çš„æ—¶å€™ä¸€ç›´ä¸æ˜ç™½maskï¼ˆåªæœ‰åœ¨Decoderçš„inputç”¨åˆ°äº†ï¼‰åˆ°åº•æ˜¯å…·ä½“æ€ä¹ˆæ“ä½œçš„ï¼Œå…¶å®ä½œè€…åœ¨åé¢æœ‰è§£é‡Šï¼Œå°±æ˜¯æŠŠæ‰€æœ‰çš„éæ³•è¿æ¥çš„scoreéƒ½è®¾ç½®æˆè´Ÿæ— ç©·ï¼Œè¿™æ ·çš„softmaxä¹‹åå¾—åˆ°çš„æƒé‡å‘é‡å°±æ˜¯é›¶äº†($e^{-\infty}$)ã€‚å®Œäº‹ã€‚ 3.2.3 Multi-Head Attentionè¿™ä¸‹å°±è®²åˆ°ç²¾é«“äº†ï¼šå¤šå¤´æ³¨æ„åŠ›ï¼ˆä¸çŸ¥é“è¿™æ ·ç¿»è¯‘ä¼šä¸ä¼šè¢«æ‰“ã€‚ã€‚ã€‚ï¼‰ã€‚å¯ä»¥è¿™ä¹ˆç†è§£ï¼Œæœ‰å¥½å¤šäººå¯¹attentionæƒé‡çš„çœ‹æ³•ä¸å¤ªä¸€æ ·ï¼Œæ‰€ä»¥æˆ‘ä»¬å°±æŠŠè¿™ä¸ªä»»åŠ¡ç»™å¾ˆå¤šäººä¸€èµ·åšï¼Œæœ€åå–å¤§å®¶çš„å…±åŒæ„è§ï¼Œæœ‰ç‚¹åƒCNNé‡Œå¥½å¤šä¸ªkernelçš„å‘³é“ã€‚ æ–‡ç« è¡¨ç¤ºï¼Œæ¯”èµ·ç›´æ¥ç”¨$d_{model}$çš„Q, K, Væ¥è¯´ï¼Œå°†Q, K, Vç”¨ä¸åŒçš„hä¸ªçº¿æ€§æŠ•å½±å¾—åˆ°çš„hä¸ª$d_v$çš„context vectorï¼Œå†concatèµ·æ¥ï¼Œè¿‡ä¸€ä¸ªçº¿æ€§å±‚çš„ç»“æœæ›´å¥½ï¼Œå¯ä»¥ç»¼åˆä¸åŒä½ç½®çš„ä¸åŒè¡¨å¾å­ç©ºé—´çš„ä¿¡æ¯ã€‚$$\text{Multihead}(Q, K, V) = \text{Concat}(\text{head}_1, \text{head}_2, â€¦, \text{head}_h)W^O\\\text{where head}_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)$$å…¶ä¸­ï¼Œ$W_i^Q\in\mathbb{R}^{d_{model}\times d_k}$ï¼Œ$W_i^K\in\mathbb{R}^{d_{model}\times d_k}$ï¼Œ$W_i^V\in\mathbb{R}^{d_{model}\times d_v}$ï¼Œç„¶å$W^O\in\mathbb{R}^{hd_v\times d_{model}}$ã€‚ åœ¨æ–‡ç« é‡Œï¼Œè®¾ç½®äº†h=8ä¸ªå¹³è¡Œæ³¨æ„å±‚ï¼ˆä¹Ÿå°±æ˜¯å¤´ï¼ˆheadï¼‰2333ï¼‰ã€‚å¯¹äºæ¯ä¸ªå±‚çš„$d_k=d_v=d_{\text{model}}/h=64$ã€‚å› ä¸ºæ¯ä¸ªå¤´éƒ½å‡å°‘äº†dimensionï¼Œæ‰€ä»¥æ•´ä½“çš„computational costå’Œsingle-head full dimensionçš„æ³¨æ„åŠ›æœºåˆ¶æ˜¯å·®ä¸å¤šçš„ã€‚ 3.2.4 Applications of Attention in our model encoder-decoder attention: æ¨¡ä»¿seq2seqæ¨¡å‹çš„æ³¨æ„åŠ›æœºåˆ¶ encoder çš„ self-attention layer decoder çš„self-attention layerï¼šå’Œä¸Šé¢çš„åŒºåˆ«å°±æ˜¯åŠ äº†masking 3.3 Position-wise Feed-Forward Networksæ¯ä¸ªFFNåŒ…æ‹¬ä¸¤æ¬¡çº¿æ€§å˜æ¢ï¼Œä¸­é—´æ˜¯ReLuçš„æ¿€æ´»å‡½æ•°ã€‚$$\text{FFN} = \max(0, xW_1+b_1)W_2+b_2$$ä¸åŒpositionçš„FFNæ˜¯ä¸€æ ·çš„ï¼Œä½†æ˜¯ä¸åŒå±‚æ˜¯ä¸åŒçš„ã€‚è¾“å…¥è¾“å‡ºç»´åº¦éƒ½æ˜¯$d_{model}=512$ï¼Œä¸­é—´å±‚çš„ç»´åº¦æ˜¯$d_{ff}=2048$ã€‚ 3.4 Embeddings and Softmaxå’Œå…¶ä»–seq transductionæ¨¡å‹ä¸€æ ·ï¼Œä¹Ÿå¾—ç”¨learned embeddingsï¼Œlearned çº¿æ€§å˜æ¢ï¼Œsoftmaxè¿™äº›ä¸œè¥¿ã€‚ä¸¤ä¸ªembeddingçš„æƒé‡æ˜¯shareçš„ã€‚embeddingå±‚ï¼Œä¼šæŠŠæƒé‡ä¹˜$\sqrt{d_{model}}â€‹$ã€‚ 3.5 Positional Encodingå› ä¸ºæ¨¡å‹æ²¡æœ‰rnnæˆ–è€…cnnï¼Œä¸ºäº†ç”¨åˆ°sequenceçš„é¡ºåºï¼Œä½œè€…å¼•å…¥äº†positional encodingï¼ˆ$dim=d_{model}$ï¼Œä¾¿äºç›¸åŠ ï¼‰æ¥injectä¸€äº›ç›¸å¯¹ä½ç½®çš„ä¿¡æ¯ã€‚$$PE(pos, 2i) = sin(pos/10000^{2i/d_{model}})\\PE(pos, 2i+1) = cos(pos/10000^{2i/d_{model}})$$ä½œè€…æµ‹è¯•ç”¨å­¦ä¹ çš„æ–¹æ³•æ¥å¾—åˆ°PEï¼Œæœ€ç»ˆå‘ç°æ•ˆæœå·®ä¸å¤šï¼Œæ‰€ä»¥æœ€åç”¨çš„æ˜¯fixedçš„ï¼Œè€Œä¸”sinusoidalçš„å¯ä»¥å¤„ç†æ›´é•¿çš„sequenceçš„æƒ…å†µã€‚ ç”¨sinusoidalå‡½æ•°çš„å¦ä¸€ä¸ªå¥½å¤„æ˜¯å¯ä»¥ç”¨å‰é¢ä½ç½®çš„å€¼çº¿æ€§è¡¨ç¤ºåé¢çš„ä½ç½®ã€‚$$\sin(\alpha+\beta) = \sin\alpha\cos\beta+\cos\alpha\sin\beta\\\cos(\alpha+\beta) = \cos\alpha\cos\beta-\sin\alpha\sin\beta$$ 4. Why Self-Attention ä¹‹æ‰€ä»¥é€‰æ‹©self-attentionï¼Œä¸»è¦å› ä¸ºä¸‰ç‚¹ï¼š æ¯å±‚çš„computational complexityï¼› å¯ä»¥è¢«parallelizeçš„è®¡ç®—é‡ï¼› ç½‘ç»œä¸­long-range dependenciesç›´æ¥çš„path lengthï¼ˆè¶ŠçŸ­è¶Šèƒ½æ–¹ä¾¿å­¦åˆ° long-range dependenciesï¼‰ã€‚ 5. Conclusionä¼˜ç‚¹ï¼š æŠ›å¼ƒäº†RNNå’ŒCNNï¼Œæå‡ºäº†Transformerï¼Œç®—æ³•çš„å¹¶è¡Œæ€§éå¸¸å¥½ï¼› Transformerçš„è®¾è®¡æœ€å¤§çš„å¸¦æ¥æ€§èƒ½æå‡çš„å…³é”®æ˜¯å°†ä»»æ„ä¸¤ä¸ªå•è¯çš„è·ç¦»æ˜¯1ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†long dependencyçš„é—®é¢˜ã€‚ ç¼ºç‚¹ï¼š Transformerä¸åƒCNNé‚£æ ·å¯ä»¥æŠ½å–å±€éƒ¨ç‰¹å¾ï¼ŒRNN + CNN + Transformerçš„ç»“åˆå¯èƒ½ä¼šå¸¦æ¥æ›´å¥½çš„æ•ˆæœï¼› ä½ç½®ä¿¡æ¯å…¶å®åœ¨NLPä¸­éå¸¸é‡è¦ï¼ŒTransformerä¸­ç”¨çš„Position Embeddingä¹Ÿä¸æ˜¯ä¸€ä¸ªæœ€ç»ˆçš„è§£å†³æ–¹æ¡ˆã€‚]]></content>
      <categories>
        <category>NLP</category>
        <category>è®ºæ–‡ç¬”è®°</category>
        <category>Attention</category>
      </categories>
      <tags>
        <tag>Attention</tag>
        <tag>Transformer</tag>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ã€è®ºæ–‡ç¬”è®°ã€‘A User Simulator for Task-Completion Dialogues]]></title>
    <url>%2F2019%2F01%2F16%2Fuser-simulator%2F</url>
    <content type="text"><![CDATA[åŸºæœ¬æ¡†æ¶ï¼ˆåŒ…å«å¯¹è¯ç³»ç»Ÿï¼‰ï¼š Abstractï¼šåšä»»åŠ¡å‹botçš„æ—¶å€™ï¼Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å¾ˆå¼ºï¼Œä½†æ˜¯æœ‰ä¸€äº›å›°éš¾ï¼š éœ€è¦å’Œç¯å¢ƒäº’åŠ¨ï¼Œå·²æœ‰çš„å®Œæ•´å¯¹è¯è®­ç»ƒæ•°æ®æ²¡ç”¨ï¼› æ¯ä¸ªä¸åŒçš„ä»»åŠ¡éƒ½éœ€è¦å„è‡ªé¢†åŸŸçš„æ ‡æ³¨æ•°æ®ï¼› æ”¶é›†äººäººå¯¹è¯æˆ–è€…äººæœºå¯¹è¯éœ€è¦é¢†åŸŸçŸ¥è¯†ã€‚ ä½†æ˜¯å•Šï¼š ====&gt;å»ºé€ æ•°æ®åº“åˆè´µåˆèŠ±æ—¶é—´ ====&gt;åªå¥½æ¨¡æ‹Ÿ ====&gt;user simulatorè¯ç”Ÿ ====&gt;Botï¼ˆagentï¼‰å…ˆç”¨simulatorå»è®­ç»ƒï¼Œæå®šäº†simulatorå°±å¯ä»¥ä¸Šçº¿ï¼ŒæŒç»­online learning Introduction:å¯¹è¯ç³»ç»Ÿä¸€èˆ¬å¦‚ Figure 1. æ‰€ç¤ºã€‚Dialongue Policy (DP)æ˜¯ä¸€ä¸ªä»»åŠ¡å‹botçš„æ ¸å¿ƒã€‚ ä¸€èˆ¬æ¥è¯´ä¼ ç»Ÿçš„Dialogue Policyï¼ˆDPï¼‰ä½¿ç”¨è§„åˆ™ç¼–ç¨‹çš„ï¼Œä½†æœ‰ç¼ºç‚¹ï¼š å¯¹äºå¤æ‚ç³»ç»Ÿï¼Œéš¾ä»¥è®¾è®¡ æœ€ä¼˜çš„policyä¹Ÿä¼šå˜åŒ–ï¼Œä¸å¥½ç»´æŠ¤ã€‚å› æ­¤ï¼Œä¸€èˆ¬ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒDPã€‚ ä¸ºå•¥è¦user simulator ? Supervised Learningï¼ˆSLï¼‰ç›‘ç£å­¦ä¹ åœ¨ä»»åŠ¡å‹çš„boté‡Œä¸è¡Œï¼š éœ€è¦ä¸“å®¶æ¥æ ‡æ³¨å¤§é‡æ•°æ®ï¼› å¤§é‡ä¸“ä¸šçš„é¢†åŸŸçŸ¥è¯†éœ€è¦å¤§é‡çš„æ•°æ®æ¥è®­ç»ƒï¼› å³ä½¿æœ‰å¤§é‡è®­ç»ƒæ•°æ®ï¼Œè¿˜æ˜¯ä¼šæœ‰å¯¹è¯ç©ºé—´æ²¡æœ‰è¢«æœç´¢åˆ°ã€‚ ç›¸åçš„ï¼ŒRLå¾ˆåŠï¼Œä¸éœ€è¦ä¸“å®¶ç”Ÿæˆçš„æ•°æ®ï¼Œç»™ä¸€ä¸ªå¥–åŠ±ä¿¡å·ï¼Œagentå°±å¯ä»¥é€šè¿‡äº¤äº’ä¼˜åŒ–DPã€‚ ä½†æ˜¯ä¸å¹¸çš„æ˜¯ï¼šRLéœ€è¦ä»ç¯å¢ƒæ¥çš„å¾ˆå¤šsampleï¼Œæ‰€ä»¥å’ŒçœŸå®ç”¨æˆ·ä»é›¶å¼€å§‹è®­ç»ƒä¸å®é™…ã€‚ ====&gt; æ‰€ä»¥éœ€è¦User Simulatorsï¼ ä¸€èˆ¬çš„æ“ä½œæ˜¯ï¼šå…ˆåœ¨simulatorä¸Šè®­ç»ƒå‡ºä¸€ä¸ªæ¯”è¾ƒå¥½çš„æ•ˆæœï¼Œå†éƒ¨ç½²åˆ°çœŸå®åœºæ™¯ä¸­ï¼ŒæŒç»­online learningã€‚ Related Workå¾ˆéš¾åˆ¤æ–­user simulatorå¥½ä¸å¥½ï¼Œæ²¡æœ‰Metricæ¥åˆ¤å®šï¼Œsoæ²¡æœ‰æ ‡å‡†æ–¹æ³•ï¼Œæ”¾æ‰‹ä¹±åšã€‚user simulationä¸»è¦æœ‰è¿™ä¹ˆå‡ ä¸ªç±»å‹ï¼š ä»ç²’åº¦ä¸Šåˆ†ï¼š åœ¨å¯¹è¯è¡Œä¸ºï¼ˆdialogue-actï¼‰ä¸Šè¿›è¡Œæ“ä½œçš„ï¼› åœ¨å¯¹è¯æ–‡æœ¬ï¼ˆutteranceï¼‰è¿›è¡Œæ“ä½œçš„ ä»æ–¹æ³•çš„è§’åº¦è®²ï¼š åŸºäºè§„åˆ™çš„ï¼ˆrule-basedï¼‰ åŸºäºæ¨¡å‹çš„ï¼ˆmodel-basedï¼‰ ä»¥å‰çš„ bi-gram æ¨¡å‹ $P(a_u |a_m)$ï¼ŒåŸºäºä¸Šä¸€ä¸ªç³»ç»Ÿè¡Œä¸º $a_m$ å»é¢„æµ‹ä¸‹ä¸€ä¸ªç”¨æˆ·è¡Œä¸º $a_u$ã€‚è¿™å°±å¾ˆå‚»ã€‚(useræœ‰å¯èƒ½æ”¹goalï¼Œçœ‹çš„ä¿¡æ¯å¤ªå°‘) åé¢ä¸¤ä¸ªåŠæ³•æ¥å¤„ç†ï¼š çœ‹æ›´é•¿çš„å¯¹è¯å†å² æŠŠuser goal æ”¾åˆ°user state modelingä¸­ seq2seqç«¯åˆ°ç«¯è§£å†³é—²èŠå¯ä»¥ï¼Œä»»åŠ¡å‹ä¸å¤ªè¡Œã€‚ æœ¬æ–‡ç”¨çš„å« agenda-based user simulation çš„æ¶æ„ï¼Œç±»ä¼¼æ ˆçš„ç»“æ„é€šè¿‡è¿›æ ˆå‡ºæ ˆæ¥ model çŠ¶æ€è½¬ç§»å’Œç”¨æˆ·è¡Œä¸ºç”Ÿæˆã€‚å¾ˆæ–¹ä¾¿ï¼Œæ˜¾æ€§encodeäº†å¯¹è¯å†å²å’Œç”¨æˆ·ç›®æ ‡ï¼ˆuser goalï¼‰ã€‚ æ€»ç»“ï¼šæ–‡ç«  ç»“åˆäº†rule-basedå’Œmodel-based çš„æ–¹æ³•: åœ¨dialog-act levelï¼Œç”¨äº†agenda-based (rule)çš„æ–¹æ³•ï¼› åœ¨nlgéƒ¨åˆ†ï¼Œç”¨äº†seq2seq (model)çš„æ–¹æ³•ã€‚ Task-completionçš„å¯¹è¯ç³»ç»Ÿï¼ˆDialogue systemï¼‰ä»»åŠ¡å‹å¯¹è¯ç³»ç»Ÿ(ä»¥è®¢ç¥¨botä¸ºä¾‹)ï¼Œé€šè¿‡nläº¤äº’ï¼Œå»è·å–å®¢æˆ·æœŸæœ›çš„ä¿¡æ¯ï¼Œæœ€ç»ˆå®ç°è®¢ç¥¨ã€‚ä»¥ï¼š æ˜¯å¦è®¢ç¥¨æˆåŠŸ æ˜¯å¦ç”µå½±æ»¡è¶³è¦æ±‚ ä¸ºæ ‡å‡†ï¼Œè¾“å‡ºä¸€ä¸ªäºŒè¿›åˆ¶ç»“æœï¼Œsuccess or failureï¼Œè¯„ä¼°ç³»ç»Ÿã€‚ æ•°æ®ï¼šç”¨Amazon Mechanical Turkï¼ˆä¼—åŒ…å¹³å°ï¼‰æ”¶é›†çš„æ•°æ®ï¼Œå†…éƒ¨æ ‡æ³¨ï¼Œ11ä¸ªintentï¼ˆi.e., informï¼Œrequestï¼Œconfirm-questionï¼Œconfirm-answerï¼Œetcï¼‰ï¼Œ29ä¸ªslotï¼ˆi.e., movie-nameï¼Œstart-timeï¼Œtheaterï¼Œnumberofpeopleï¼Œetcï¼‰ã€‚ ä¸€å…±æ ‡æ³¨äº†280ä¸ªå¯¹è¯ï¼Œå¯¹è¯å¹³å‡11è½®ã€‚ User SimulatorUser GoalTC Botçš„user simulatorç¬¬ä¸€æ­¥æ˜¯ç”Ÿæˆuser goalã€‚agentä¸çŸ¥é“user goalï¼Œä½†æ˜¯è¦å¸®åŠ©useræ¥å®Œæˆä»–çš„goalã€‚user goalçš„å®šä¹‰åˆ†ä¸¤ä¸ªéƒ¨åˆ†ï¼š inform_slots: åŒ…å«äº†constraintsï¼ˆCï¼‰ request_slots: unkï¼ˆRï¼‰ åˆå¯ä»¥åˆ†æˆï¼š å¿…é¡»æœ‰çš„slotsï¼ˆrequired slotsï¼‰ é€‰æ‹©æœ‰çš„slotsï¼ˆoptional slotsï¼Œi.e., ticketå°±æ˜¯request slots é‡Œçš„å¿…é¡»é¡¹ï¼‰ã€‚ Goalæ˜¯åœ¨labeled dataseté‡Œç”Ÿæˆçš„ï¼Œä¸¤ä¸ªæœºåˆ¶ï¼š åœ¨ç¬¬ä¸€ä¸ªç”¨æˆ·è½®æå–æ‰€æœ‰çš„slotsã€‚å¯¹äºæ‰€æœ‰çš„slotsï¼Œåœ¨æ‰€æœ‰çš„ç”¨æˆ·è½®é‡Œæå–ç¬¬ä¸€æ¬¡å‡ºç°çš„ã€‚ æ¯æ¬¡è·‘å¯¹è¯çš„æ—¶å€™ï¼Œå°±å…ˆsampleä¸€ä¸ªuser goalã€‚ User Actionç¬¬ä¸€è½®çš„action samplingï¼šè¦åŠ ä¸€äº›é™åˆ¶ï¼ˆæ¯”å¦‚é€šå¸¸æ˜¯request turnï¼Œè‡³å°‘ä¸€ä¸ªinform slotï¼Œmovie_nameå¿…é¡»åœ¨ï¼Œç­‰ç­‰ï¼‰ã€‚ å¦‚æœä¸ç”¨NLGï¼ŒNLUçš„è¯ï¼Œè¿˜è¦åŠ å…¥å™ªå£°æ¥æ¨¡æ‹ŸNLGå’ŒNLUè¿‡ç¨‹äº§ç”Ÿçš„å™ªéŸ³ï¼Œå»è®­ç»ƒDMéƒ¨åˆ†ã€‚ Dialogue Statusä¸‰ä¸ªå¯¹åŒ–çŠ¶æ€ï¼š no_outcome_yet success failure å…·ä½“æƒ…å†µå…·ä½“è®¨è®ºã€‚ NLUIOB-format slots tags + Intent tags æœ€åçš„hidden layeråˆ¤æ–­ intentã€‚ NLGåŸºäºTemplateçš„NLGï¼šdialog-act è¢«foundåœ¨æ¨¡æ¿ä¸­çš„ï¼Œå¥—æ¨¡æ¿å¥å‹ã€‚åŸºäºModelçš„NLGï¼šæ²¡å‘ç°çš„ï¼Œç”¨modelç”Ÿæˆã€‚ï¼ˆè¿™ä¸€ç‚¹æ„Ÿè§‰å¾ˆæ‰¯ï¼Œéƒ½æ²¡è§è¿‡ï¼Œå’‹ç”Ÿæˆï¼Œæ•°æ®é‡è‚¯å®šä¸å¤Ÿå•Šã€‚ï¼‰ UsagesTask-completing Dialogue Settingï¼šä»»åŠ¡å‹Botï¼ˆè®¢ç¥¨ï¼‰ï¼Œè¡¡é‡ agentçš„Metricsä¸ºï¼š1. success rateï¼›2. average rewardï¼›3. average turnsã€‚KB-InfoBotï¼ˆç®€å•ç‚¹ï¼Œagentå’Œuseréƒ½åªæœ‰requestå’Œinformï¼‰ï¼šé—®ç­”Botï¼ˆç”µå½±ä¿¡æ¯ï¼‰ DiscussionRule-basedçš„ user simulation å¾ˆsafeï¼Œä½†æ˜¯å¾ˆè€—æ—¶ï¼Œå› ä¸ºè¦æ‰‹åŠ¨åˆ¶å®šå„ç§è§„åˆ™ã€‚ä¸¤ä¸ªä¼˜åŒ–æ–¹å‘ï¼š åŒ…å«user goalçš„æ”¹å˜ï¼ˆå·²åšï¼‰å®ç°Model-based çš„simulatorï¼Œä¼˜ç‚¹æ˜¯æ³›åŒ–æ€§èƒ½å¥½ï¼Œç¼ºç‚¹æ˜¯1. éœ€è¦å¤§é‡æ•°æ®ï¼Œ 2. ä¸‡ä¸€æœ‰æ¼æ´ï¼ŒRL agent ä¼šæŠ“ä½è¿™ä¸ªæ¼æ´ï¼Œå‡å‡çš„æˆåŠŸï¼Œä½ ä»¥ä¸ºsuccessäº†ï¼Œå…¶å®éƒ½æ˜¯RL agentæŠ“ä½äº†loopholeç»™ä½ çš„å‡è±¡ã€‚ æ€»ç»“ï¼šï¼ˆæ ¹æ®ã€ŠAgenda-Based User Simulation for bootstrapping a POMDP Dialogue Systemã€‹by J. Schatzmannï¼‰ è¯­ä¹‰å±‚çš„ User Simulationäººæœºå¯¹è¯å¯ä»¥çœ‹æˆæ˜¯çŠ¶æ€è½¬ç§»ï¼ˆstate transitionï¼‰å’Œå¯¹è¯è¡Œä¸ºï¼ˆDialogï¼‰çš„åºåˆ—ï¼šç”¨æˆ·æ ¹æ®çŠ¶æ€ S (æˆ–åŠ ä¸Šæœºå™¨äººçš„ $a_m$ï¼Œç¬¬ä¸€è½®å¯èƒ½æ²¡æœ‰$a_m$)ï¼Œé‡‡å–è¡ŒåŠ¨ $a_u$, æŠŠçŠ¶æ€è½¬ç§»åˆ°$Sâ€™$ã€‚æ”¶åˆ°agentè¡ŒåŠ¨ $a_m$ï¼Œå†æ ¹æ® $Sâ€™$ ï¼Œå†æŠŠçŠ¶æ€è½¬ç§»åˆ° $Sâ€™â€™$ã€‚è¿™ä¸ªuserè¡Œä¸ºå¯ä»¥è¢«åˆ†è§£ä¸ºä¸‰ä¸ªæ¨¡å‹ï¼š$P(a_u|S)$ è¡Œä¸ºé€‰æ‹©ï¼Œ$P(Sâ€™|a_u, S)$ çŠ¶æ€è½¬ç§»ï¼ˆç”¨æˆ·è¡Œä¸ºï¼‰ï¼Œ$P(Sâ€™â€™|a_m,Sâ€™)$ çŠ¶æ€è½¬ç§»ï¼ˆç³»ç»Ÿè¡Œä¸ºï¼‰ã€‚ åŸºäºGoalå’ŒAgentçš„çŠ¶æ€è¡¨ç¤ºç”¨æˆ·çŠ¶æ€ï¼ˆUser Stateï¼‰ç”±ç”¨æˆ·ç›®æ ‡ï¼ˆGoalï¼‰åŠè®®ç¨‹ï¼ˆAgendaï¼‰æ„æˆã€‚ Goalç”±Constraintï¼ˆCï¼‰ï¼ˆæ¯”å¦‚è¦å¸‚ä¸­å¿ƒçš„å•¤é…’é…’å§ï¼‰å’ŒRequestï¼ˆRï¼‰ï¼ˆæ¯”å¦‚é…’å§ç”µè¯æ˜¯å¤šå°‘ï¼‰æ„æˆã€‚ Agendaæ˜¯ä¸€ä¸ªç±»ä¼¼æ ˆçš„ç»“æ„ï¼ŒåŒ…å«äº†åœ¨æ’é˜Ÿä¸­çš„ï¼Œç”¨æ¥å¼•å‡ºç›®æ ‡ä¸­æ˜ç¡®çš„ä¿¡æ¯çš„ç”¨æˆ·è¡Œä¸ºã€‚åœ¨å¯¹è¯å¼€å§‹çš„æ—¶å€™ï¼Œç”¨æ•°æ®åº“éšæœºç”Ÿæˆä¸€ä¸ªæ–°çš„Goalã€‚ç„¶åï¼Œä»Goalé‡Œçš„å†…å®¹æ¥åˆå§‹åŒ–Agendaï¼ŒæŠŠGoalä¸­çš„ C éƒ½convertæˆ InformåŠ¨ä½œï¼ŒæŠŠGoalä¸­çš„ R éƒ½convertæˆ RequeståŠ¨ä½œï¼Œå†åœ¨æœ€ååŠ ä¸€ä¸ªbyeåŠ¨ä½œã€‚æœ‰æ–°çš„ $a_mâ€‹$ çš„æ—¶å€™ï¼Œæ–°çš„user acts ä¼šè¢«å‹è¿›æ ˆï¼Œä¸éœ€è¦çš„ä¼šè¢«å‡ºæ ˆã€‚å…·ä½“å®ç°æ–¹æ³•ï¼ˆæ¡†æ¶å’Œæ•°æ®ç»“æ„ï¼‰ï¼Œåé¢åˆ†æmiulabçš„simulatoræºç çš„æ—¶å€™ä¼šå†™ã€‚ ä¸Šå›¾æè¿°äº†Agendaéšç€$a_m$ï¼Œ$a_u$çš„çŠ¶æ€è½¬ç§»è¿‡ç¨‹ï¼ˆè¿›æ ˆå’Œå‡ºæ ˆï¼‰ã€‚ ä¸Šå›¾æè¿°äº†æ— NLUå’ŒNLGçš„è®­ç»ƒã€‚]]></content>
      <categories>
        <category>NLP</category>
        <category>è®ºæ–‡ç¬”è®°</category>
        <category>Bot</category>
      </categories>
      <tags>
        <tag>Chatbot</tag>
        <tag>User Simulator</tag>
        <tag>Reinforcement Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[å‰è¨€]]></title>
    <url>%2F2019%2F01%2F11%2Ffirst-post%2F</url>
    <content type="text"><![CDATA[æ¬¢è¿æ¥åˆ°ç“¦ç‰¹å…°è’‚æ–¯ã€‚ç¬”è€…æ˜¯ä¸€ä¸ªç›¸ä¿¡äºšç‰¹å…°è’‚æ–¯æ›¾ç»å­˜åœ¨çš„äº”å²æŠ¬å¤´å›¢â€”akaç“¦ç ¾ã€‚ ä¸å®šæœŸæ›´æ–°NLPçš„å¹²è´§ï¼Œåˆšå¼€å§‹å†™åšå®¢ï¼Œå¸Œæœ›è‡ªå·±èƒ½åšæŒä¸‹å»ï¼Œè¯·å¤§å®¶å¤šå¤šæŒ‡æ•™ã€‚ è¯•ä¸€ä¸‹å›¾ç‰‡å’‹æ”¾ã€‚2333ã€‚]]></content>
  </entry>
</search>
